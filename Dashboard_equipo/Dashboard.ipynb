{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ac56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, roc_auc_score, roc_curve, classification_report, f1_score, precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c782006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5315 entries, 0 to 5314\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            5315 non-null   int64  \n",
      " 1   listing_url                                   5315 non-null   object \n",
      " 2   scrape_id                                     5315 non-null   int64  \n",
      " 3   last_scraped                                  5315 non-null   object \n",
      " 4   source                                        5315 non-null   object \n",
      " 5   name                                          5315 non-null   object \n",
      " 6   description                                   5315 non-null   object \n",
      " 7   neighborhood_overview                         5315 non-null   object \n",
      " 8   picture_url                                   5315 non-null   object \n",
      " 9   host_id                                       5315 non-null   int64  \n",
      " 10  host_url                                      5315 non-null   object \n",
      " 11  host_name                                     5315 non-null   object \n",
      " 12  host_since                                    5117 non-null   object \n",
      " 13  host_location                                 5315 non-null   object \n",
      " 14  host_about                                    5315 non-null   object \n",
      " 15  host_response_time                            5315 non-null   object \n",
      " 16  host_response_rate                            5315 non-null   object \n",
      " 17  host_acceptance_rate                          5315 non-null   object \n",
      " 18  host_is_superhost                             5315 non-null   object \n",
      " 19  host_thumbnail_url                            5315 non-null   object \n",
      " 20  host_picture_url                              5315 non-null   object \n",
      " 21  host_neighbourhood                            5315 non-null   object \n",
      " 22  host_listings_count                           5315 non-null   float64\n",
      " 23  host_total_listings_count                     5315 non-null   float64\n",
      " 24  host_verifications                            5315 non-null   object \n",
      " 25  host_has_profile_pic                          5315 non-null   object \n",
      " 26  host_identity_verified                        5315 non-null   object \n",
      " 27  neighbourhood                                 5315 non-null   object \n",
      " 28  neighbourhood_cleansed                        5315 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  5315 non-null   object \n",
      " 30  latitude                                      5315 non-null   float64\n",
      " 31  longitude                                     5315 non-null   float64\n",
      " 32  property_type                                 5315 non-null   object \n",
      " 33  room_type                                     5315 non-null   object \n",
      " 34  accommodates                                  5315 non-null   int64  \n",
      " 35  bathrooms                                     5315 non-null   float64\n",
      " 36  bathrooms_text                                5315 non-null   object \n",
      " 37  bedrooms                                      5315 non-null   float64\n",
      " 38  beds                                          5315 non-null   float64\n",
      " 39  amenities                                     5315 non-null   object \n",
      " 40  price                                         5315 non-null   float64\n",
      " 41  minimum_nights                                5315 non-null   int64  \n",
      " 42  maximum_nights                                5315 non-null   int64  \n",
      " 43  minimum_minimum_nights                        5315 non-null   float64\n",
      " 44  maximum_minimum_nights                        5315 non-null   float64\n",
      " 45  minimum_maximum_nights                        5315 non-null   float64\n",
      " 46  maximum_maximum_nights                        5315 non-null   float64\n",
      " 47  minimum_nights_avg_ntm                        5315 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        5315 non-null   float64\n",
      " 49  calendar_updated                              5315 non-null   object \n",
      " 50  has_availability                              5315 non-null   object \n",
      " 51  availability_30                               5315 non-null   int64  \n",
      " 52  availability_60                               5315 non-null   int64  \n",
      " 53  availability_90                               5315 non-null   int64  \n",
      " 54  availability_365                              5315 non-null   int64  \n",
      " 55  calendar_last_scraped                         5315 non-null   object \n",
      " 56  number_of_reviews                             5315 non-null   int64  \n",
      " 57  number_of_reviews_ltm                         5315 non-null   int64  \n",
      " 58  number_of_reviews_l30d                        5315 non-null   int64  \n",
      " 59  availability_eoy                              5315 non-null   int64  \n",
      " 60  number_of_reviews_ly                          5315 non-null   int64  \n",
      " 61  estimated_occupancy_l365d                     5315 non-null   int64  \n",
      " 62  estimated_revenue_l365d                       5315 non-null   float64\n",
      " 63  first_review                                  4169 non-null   object \n",
      " 64  last_review                                   4169 non-null   object \n",
      " 65  review_scores_rating                          5315 non-null   float64\n",
      " 66  review_scores_accuracy                        5315 non-null   float64\n",
      " 67  review_scores_cleanliness                     5315 non-null   float64\n",
      " 68  review_scores_checkin                         5315 non-null   float64\n",
      " 69  review_scores_communication                   5315 non-null   float64\n",
      " 70  review_scores_location                        5315 non-null   float64\n",
      " 71  review_scores_value                           5315 non-null   float64\n",
      " 72  license                                       5315 non-null   object \n",
      " 73  instant_bookable                              5315 non-null   object \n",
      " 74  calculated_host_listings_count                5315 non-null   int64  \n",
      " 75  calculated_host_listings_count_entire_homes   5315 non-null   int64  \n",
      " 76  calculated_host_listings_count_private_rooms  5315 non-null   int64  \n",
      " 77  calculated_host_listings_count_shared_rooms   5315 non-null   int64  \n",
      " 78  reviews_per_month                             5315 non-null   float64\n",
      "dtypes: float64(23), int64(20), object(36)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "Estocolmo = pd.read_csv('Datasets/estocolmofinal.csv')\n",
    "Estocolmo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5020a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasas de cambio\n",
    "# Tasas de cambio a EUR\n",
    "exchange_rates = {\n",
    "    'MXN': 0.052,  # México\n",
    "    'SEK': 0.088,  # Suecia\n",
    "    'EUR': 1.0     # Alemania y España\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cce12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar price y estimated_revenue_l365d\n",
    "Estocolmo['price_eur'] = Estocolmo['price'] * exchange_rates['SEK']\n",
    "Estocolmo['estimated_revenue_eur'] = Estocolmo['estimated_revenue_l365d'] * exchange_rates['SEK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829142af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5315.000000\n",
       "mean       156.997712\n",
       "std        412.342051\n",
       "min          9.240000\n",
       "25%         88.000000\n",
       "50%        116.248000\n",
       "75%        156.684000\n",
       "max      12426.040000\n",
       "Name: price_eur, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estocolmo['price_eur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712f40a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      5315.000000\n",
       "mean       1784.064911\n",
       "std        4685.705123\n",
       "min         105.000000\n",
       "25%        1000.000000\n",
       "50%        1321.000000\n",
       "75%        1780.500000\n",
       "max      141205.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estocolmo['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95189b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_cat\n",
       "Low price     3986\n",
       "High price    1329\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Price_Cat Estomocol\n",
    "umbral_precio_Estocolmo = Estocolmo['price_eur'].quantile(0.75) #1780\n",
    "Estocolmo['price_cat'] = np.where(Estocolmo['price_eur'] >= umbral_precio_Estocolmo, 'High price', 'Low price')\n",
    "Estocolmo['price_cat'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230ef7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5315 entries, 0 to 5314\n",
      "Data columns (total 82 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            5315 non-null   int64  \n",
      " 1   listing_url                                   5315 non-null   object \n",
      " 2   scrape_id                                     5315 non-null   int64  \n",
      " 3   last_scraped                                  5315 non-null   object \n",
      " 4   source                                        5315 non-null   object \n",
      " 5   name                                          5315 non-null   object \n",
      " 6   description                                   5315 non-null   object \n",
      " 7   neighborhood_overview                         5315 non-null   object \n",
      " 8   picture_url                                   5315 non-null   object \n",
      " 9   host_id                                       5315 non-null   int64  \n",
      " 10  host_url                                      5315 non-null   object \n",
      " 11  host_name                                     5315 non-null   object \n",
      " 12  host_since                                    5117 non-null   object \n",
      " 13  host_location                                 5315 non-null   object \n",
      " 14  host_about                                    5315 non-null   object \n",
      " 15  host_response_time                            5315 non-null   object \n",
      " 16  host_response_rate                            5315 non-null   object \n",
      " 17  host_acceptance_rate                          5315 non-null   object \n",
      " 18  host_is_superhost                             5315 non-null   object \n",
      " 19  host_thumbnail_url                            5315 non-null   object \n",
      " 20  host_picture_url                              5315 non-null   object \n",
      " 21  host_neighbourhood                            5315 non-null   object \n",
      " 22  host_listings_count                           5315 non-null   float64\n",
      " 23  host_total_listings_count                     5315 non-null   float64\n",
      " 24  host_verifications                            5315 non-null   object \n",
      " 25  host_has_profile_pic                          5315 non-null   object \n",
      " 26  host_identity_verified                        5315 non-null   object \n",
      " 27  neighbourhood                                 5315 non-null   object \n",
      " 28  neighbourhood_cleansed                        5315 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  5315 non-null   object \n",
      " 30  latitude                                      5315 non-null   float64\n",
      " 31  longitude                                     5315 non-null   float64\n",
      " 32  property_type                                 5315 non-null   object \n",
      " 33  room_type                                     5315 non-null   object \n",
      " 34  accommodates                                  5315 non-null   int64  \n",
      " 35  bathrooms                                     5315 non-null   float64\n",
      " 36  bathrooms_text                                5315 non-null   object \n",
      " 37  bedrooms                                      5315 non-null   float64\n",
      " 38  beds                                          5315 non-null   float64\n",
      " 39  amenities                                     5315 non-null   object \n",
      " 40  price                                         5315 non-null   float64\n",
      " 41  minimum_nights                                5315 non-null   int64  \n",
      " 42  maximum_nights                                5315 non-null   int64  \n",
      " 43  minimum_minimum_nights                        5315 non-null   float64\n",
      " 44  maximum_minimum_nights                        5315 non-null   float64\n",
      " 45  minimum_maximum_nights                        5315 non-null   float64\n",
      " 46  maximum_maximum_nights                        5315 non-null   float64\n",
      " 47  minimum_nights_avg_ntm                        5315 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        5315 non-null   float64\n",
      " 49  calendar_updated                              5315 non-null   object \n",
      " 50  has_availability                              5315 non-null   object \n",
      " 51  availability_30                               5315 non-null   int64  \n",
      " 52  availability_60                               5315 non-null   int64  \n",
      " 53  availability_90                               5315 non-null   int64  \n",
      " 54  availability_365                              5315 non-null   int64  \n",
      " 55  calendar_last_scraped                         5315 non-null   object \n",
      " 56  number_of_reviews                             5315 non-null   int64  \n",
      " 57  number_of_reviews_ltm                         5315 non-null   int64  \n",
      " 58  number_of_reviews_l30d                        5315 non-null   int64  \n",
      " 59  availability_eoy                              5315 non-null   int64  \n",
      " 60  number_of_reviews_ly                          5315 non-null   int64  \n",
      " 61  estimated_occupancy_l365d                     5315 non-null   int64  \n",
      " 62  estimated_revenue_l365d                       5315 non-null   float64\n",
      " 63  first_review                                  4169 non-null   object \n",
      " 64  last_review                                   4169 non-null   object \n",
      " 65  review_scores_rating                          5315 non-null   float64\n",
      " 66  review_scores_accuracy                        5315 non-null   float64\n",
      " 67  review_scores_cleanliness                     5315 non-null   float64\n",
      " 68  review_scores_checkin                         5315 non-null   float64\n",
      " 69  review_scores_communication                   5315 non-null   float64\n",
      " 70  review_scores_location                        5315 non-null   float64\n",
      " 71  review_scores_value                           5315 non-null   float64\n",
      " 72  license                                       5315 non-null   object \n",
      " 73  instant_bookable                              5315 non-null   object \n",
      " 74  calculated_host_listings_count                5315 non-null   int64  \n",
      " 75  calculated_host_listings_count_entire_homes   5315 non-null   int64  \n",
      " 76  calculated_host_listings_count_private_rooms  5315 non-null   int64  \n",
      " 77  calculated_host_listings_count_shared_rooms   5315 non-null   int64  \n",
      " 78  reviews_per_month                             5315 non-null   float64\n",
      " 79  price_eur                                     5315 non-null   float64\n",
      " 80  estimated_revenue_eur                         5315 non-null   float64\n",
      " 81  price_cat                                     5315 non-null   object \n",
      "dtypes: float64(25), int64(20), object(37)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Estocolmo.drop(['price','estimated_revenue_l365d'], axis=1)\n",
    "Estocolmo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62850e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26401 entries, 0 to 26400\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            26401 non-null  float64\n",
      " 1   listing_url                                   26401 non-null  object \n",
      " 2   scrape_id                                     26401 non-null  float64\n",
      " 3   last_scraped                                  26401 non-null  object \n",
      " 4   source                                        26401 non-null  object \n",
      " 5   name                                          26401 non-null  object \n",
      " 6   description                                   26401 non-null  object \n",
      " 7   neighborhood_overview                         26401 non-null  object \n",
      " 8   picture_url                                   26401 non-null  object \n",
      " 9   host_id                                       26401 non-null  int64  \n",
      " 10  host_url                                      26401 non-null  object \n",
      " 11  host_name                                     26401 non-null  object \n",
      " 12  host_since                                    26401 non-null  object \n",
      " 13  host_location                                 26401 non-null  object \n",
      " 14  host_about                                    26401 non-null  object \n",
      " 15  host_response_time                            26401 non-null  object \n",
      " 16  host_response_rate                            26401 non-null  int64  \n",
      " 17  host_acceptance_rate                          26401 non-null  int64  \n",
      " 18  host_is_superhost                             26401 non-null  object \n",
      " 19  host_thumbnail_url                            26401 non-null  object \n",
      " 20  host_picture_url                              26401 non-null  object \n",
      " 21  host_neighbourhood                            26401 non-null  object \n",
      " 22  host_listings_count                           26401 non-null  int64  \n",
      " 23  host_total_listings_count                     26401 non-null  int64  \n",
      " 24  host_verifications                            26401 non-null  object \n",
      " 25  host_has_profile_pic                          26401 non-null  object \n",
      " 26  host_identity_verified                        26401 non-null  object \n",
      " 27  neighbourhood                                 26401 non-null  object \n",
      " 28  neighbourhood_cleansed                        26401 non-null  object \n",
      " 29  latitude                                      26401 non-null  float64\n",
      " 30  longitude                                     26401 non-null  float64\n",
      " 31  property_type                                 26401 non-null  object \n",
      " 32  room_type                                     26401 non-null  object \n",
      " 33  accommodates                                  26401 non-null  int64  \n",
      " 34  bathrooms                                     26401 non-null  float64\n",
      " 35  bathrooms_text                                26401 non-null  object \n",
      " 36  bedrooms                                      26401 non-null  int64  \n",
      " 37  beds                                          26401 non-null  int64  \n",
      " 38  amenities                                     26401 non-null  object \n",
      " 39  price                                         26401 non-null  float64\n",
      " 40  minimum_nights                                26401 non-null  int64  \n",
      " 41  maximum_nights                                26401 non-null  int64  \n",
      " 42  minimum_minimum_nights                        26401 non-null  int64  \n",
      " 43  maximum_minimum_nights                        26401 non-null  int64  \n",
      " 44  minimum_maximum_nights                        26401 non-null  int64  \n",
      " 45  maximum_maximum_nights                        26401 non-null  int64  \n",
      " 46  minimum_nights_avg_ntm                        26401 non-null  float64\n",
      " 47  maximum_nights_avg_ntm                        26401 non-null  float64\n",
      " 48  has_availability                              26401 non-null  object \n",
      " 49  availability_30                               26401 non-null  int64  \n",
      " 50  availability_60                               26401 non-null  int64  \n",
      " 51  availability_90                               26401 non-null  int64  \n",
      " 52  availability_365                              26401 non-null  int64  \n",
      " 53  calendar_last_scraped                         26401 non-null  object \n",
      " 54  number_of_reviews                             26401 non-null  int64  \n",
      " 55  number_of_reviews_ltm                         26401 non-null  int64  \n",
      " 56  number_of_reviews_l30d                        26401 non-null  int64  \n",
      " 57  availability_eoy                              26401 non-null  int64  \n",
      " 58  number_of_reviews_ly                          26401 non-null  int64  \n",
      " 59  estimated_occupancy_l365d                     26401 non-null  int64  \n",
      " 60  estimated_revenue_l365d                       26401 non-null  int64  \n",
      " 61  first_review                                  26401 non-null  object \n",
      " 62  last_review                                   26401 non-null  object \n",
      " 63  review_scores_rating                          26401 non-null  float64\n",
      " 64  review_scores_accuracy                        26401 non-null  float64\n",
      " 65  review_scores_cleanliness                     26401 non-null  float64\n",
      " 66  review_scores_checkin                         26401 non-null  float64\n",
      " 67  review_scores_communication                   26401 non-null  float64\n",
      " 68  review_scores_location                        26401 non-null  float64\n",
      " 69  review_scores_value                           26401 non-null  float64\n",
      " 70  instant_bookable                              26401 non-null  object \n",
      " 71  calculated_host_listings_count                26401 non-null  int64  \n",
      " 72  calculated_host_listings_count_entire_homes   26401 non-null  int64  \n",
      " 73  calculated_host_listings_count_private_rooms  26401 non-null  int64  \n",
      " 74  calculated_host_listings_count_shared_rooms   26401 non-null  int64  \n",
      " 75  reviews_per_month                             26401 non-null  float64\n",
      "dtypes: float64(16), int64(29), object(31)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Mexico = pd.read_csv('Datasets/Mexico_City.csv')\n",
    "Mexico.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5facdbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mexico['price_eur'] = Mexico['price'] * exchange_rates['MXN']\n",
    "Mexico['estimated_revenue_eur'] = Mexico['estimated_revenue_l365d'] * exchange_rates['MXN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57779646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26401.000000\n",
       "mean        54.871055\n",
       "std         29.444398\n",
       "min          3.432000\n",
       "25%         30.264000\n",
       "50%         50.076000\n",
       "75%         70.278000\n",
       "max        152.464000\n",
       "Name: price_eur, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mexico['price_eur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1da8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26401.000000\n",
       "mean      1055.212587\n",
       "std        566.238420\n",
       "min         66.000000\n",
       "25%        582.000000\n",
       "50%        963.000000\n",
       "75%       1351.500000\n",
       "max       2932.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mexico['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a79fbcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_cat\n",
       "Low price     19607\n",
       "High price     6794\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de price_cat\n",
    "umbral_precio_Mexico = Mexico['price_eur'].quantile(0.75)\n",
    "Mexico['price_cat'] = np.where(Mexico['price_eur'] >= umbral_precio_Mexico, 'High price', 'Low price')\n",
    "Mexico['price_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "344d1fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26401 entries, 0 to 26400\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            26401 non-null  float64\n",
      " 1   listing_url                                   26401 non-null  object \n",
      " 2   scrape_id                                     26401 non-null  float64\n",
      " 3   last_scraped                                  26401 non-null  object \n",
      " 4   source                                        26401 non-null  object \n",
      " 5   name                                          26401 non-null  object \n",
      " 6   description                                   26401 non-null  object \n",
      " 7   neighborhood_overview                         26401 non-null  object \n",
      " 8   picture_url                                   26401 non-null  object \n",
      " 9   host_id                                       26401 non-null  int64  \n",
      " 10  host_url                                      26401 non-null  object \n",
      " 11  host_name                                     26401 non-null  object \n",
      " 12  host_since                                    26401 non-null  object \n",
      " 13  host_location                                 26401 non-null  object \n",
      " 14  host_about                                    26401 non-null  object \n",
      " 15  host_response_time                            26401 non-null  object \n",
      " 16  host_response_rate                            26401 non-null  int64  \n",
      " 17  host_acceptance_rate                          26401 non-null  int64  \n",
      " 18  host_is_superhost                             26401 non-null  object \n",
      " 19  host_thumbnail_url                            26401 non-null  object \n",
      " 20  host_picture_url                              26401 non-null  object \n",
      " 21  host_neighbourhood                            26401 non-null  object \n",
      " 22  host_listings_count                           26401 non-null  int64  \n",
      " 23  host_total_listings_count                     26401 non-null  int64  \n",
      " 24  host_verifications                            26401 non-null  object \n",
      " 25  host_has_profile_pic                          26401 non-null  object \n",
      " 26  host_identity_verified                        26401 non-null  object \n",
      " 27  neighbourhood                                 26401 non-null  object \n",
      " 28  neighbourhood_cleansed                        26401 non-null  object \n",
      " 29  latitude                                      26401 non-null  float64\n",
      " 30  longitude                                     26401 non-null  float64\n",
      " 31  property_type                                 26401 non-null  object \n",
      " 32  room_type                                     26401 non-null  object \n",
      " 33  accommodates                                  26401 non-null  int64  \n",
      " 34  bathrooms                                     26401 non-null  float64\n",
      " 35  bathrooms_text                                26401 non-null  object \n",
      " 36  bedrooms                                      26401 non-null  int64  \n",
      " 37  beds                                          26401 non-null  int64  \n",
      " 38  amenities                                     26401 non-null  object \n",
      " 39  price                                         26401 non-null  float64\n",
      " 40  minimum_nights                                26401 non-null  int64  \n",
      " 41  maximum_nights                                26401 non-null  int64  \n",
      " 42  minimum_minimum_nights                        26401 non-null  int64  \n",
      " 43  maximum_minimum_nights                        26401 non-null  int64  \n",
      " 44  minimum_maximum_nights                        26401 non-null  int64  \n",
      " 45  maximum_maximum_nights                        26401 non-null  int64  \n",
      " 46  minimum_nights_avg_ntm                        26401 non-null  float64\n",
      " 47  maximum_nights_avg_ntm                        26401 non-null  float64\n",
      " 48  has_availability                              26401 non-null  object \n",
      " 49  availability_30                               26401 non-null  int64  \n",
      " 50  availability_60                               26401 non-null  int64  \n",
      " 51  availability_90                               26401 non-null  int64  \n",
      " 52  availability_365                              26401 non-null  int64  \n",
      " 53  calendar_last_scraped                         26401 non-null  object \n",
      " 54  number_of_reviews                             26401 non-null  int64  \n",
      " 55  number_of_reviews_ltm                         26401 non-null  int64  \n",
      " 56  number_of_reviews_l30d                        26401 non-null  int64  \n",
      " 57  availability_eoy                              26401 non-null  int64  \n",
      " 58  number_of_reviews_ly                          26401 non-null  int64  \n",
      " 59  estimated_occupancy_l365d                     26401 non-null  int64  \n",
      " 60  estimated_revenue_l365d                       26401 non-null  int64  \n",
      " 61  first_review                                  26401 non-null  object \n",
      " 62  last_review                                   26401 non-null  object \n",
      " 63  review_scores_rating                          26401 non-null  float64\n",
      " 64  review_scores_accuracy                        26401 non-null  float64\n",
      " 65  review_scores_cleanliness                     26401 non-null  float64\n",
      " 66  review_scores_checkin                         26401 non-null  float64\n",
      " 67  review_scores_communication                   26401 non-null  float64\n",
      " 68  review_scores_location                        26401 non-null  float64\n",
      " 69  review_scores_value                           26401 non-null  float64\n",
      " 70  instant_bookable                              26401 non-null  object \n",
      " 71  calculated_host_listings_count                26401 non-null  int64  \n",
      " 72  calculated_host_listings_count_entire_homes   26401 non-null  int64  \n",
      " 73  calculated_host_listings_count_private_rooms  26401 non-null  int64  \n",
      " 74  calculated_host_listings_count_shared_rooms   26401 non-null  int64  \n",
      " 75  reviews_per_month                             26401 non-null  float64\n",
      " 76  price_eur                                     26401 non-null  float64\n",
      " 77  estimated_revenue_eur                         26401 non-null  float64\n",
      " 78  price_cat                                     26401 non-null  object \n",
      "dtypes: float64(18), int64(29), object(32)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "Mexico.drop(['price', 'estimated_revenue_l365d'], axis=1)\n",
    "Mexico.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a61e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14187 entries, 0 to 14186\n",
      "Data columns (total 87 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Unnamed: 0                                    14187 non-null  int64  \n",
      " 1   listing_url                                   14187 non-null  object \n",
      " 2   last_scraped                                  14187 non-null  object \n",
      " 3   source                                        14187 non-null  object \n",
      " 4   name                                          14187 non-null  object \n",
      " 5   description                                   14187 non-null  object \n",
      " 6   neighborhood_overview                         14187 non-null  object \n",
      " 7   picture_url                                   14187 non-null  object \n",
      " 8   host_id                                       14187 non-null  int64  \n",
      " 9   host_url                                      14187 non-null  object \n",
      " 10  host_name                                     14187 non-null  object \n",
      " 11  host_since                                    14187 non-null  object \n",
      " 12  host_location                                 14187 non-null  object \n",
      " 13  host_about                                    14187 non-null  object \n",
      " 14  host_response_time                            14187 non-null  object \n",
      " 15  host_is_superhost                             14187 non-null  object \n",
      " 16  host_thumbnail_url                            14187 non-null  object \n",
      " 17  host_picture_url                              14187 non-null  object \n",
      " 18  host_neighbourhood                            14187 non-null  object \n",
      " 19  host_verifications                            14187 non-null  object \n",
      " 20  host_has_profile_pic                          14187 non-null  object \n",
      " 21  host_identity_verified                        14187 non-null  object \n",
      " 22  neighbourhood                                 14187 non-null  object \n",
      " 23  neighbourhood_cleansed                        14187 non-null  object \n",
      " 24  neighbourhood_group_cleansed                  14187 non-null  object \n",
      " 25  latitude                                      14187 non-null  float64\n",
      " 26  longitude                                     14187 non-null  float64\n",
      " 27  property_type                                 14187 non-null  object \n",
      " 28  room_type                                     14187 non-null  object \n",
      " 29  bathrooms_text                                14187 non-null  object \n",
      " 30  amenities                                     14187 non-null  object \n",
      " 31  has_availability                              14187 non-null  object \n",
      " 32  calendar_last_scraped                         14187 non-null  object \n",
      " 33  first_review                                  14187 non-null  object \n",
      " 34  last_review                                   14187 non-null  object \n",
      " 35  license                                       14187 non-null  object \n",
      " 36  instant_bookable                              14187 non-null  object \n",
      " 37  host_response_rate                            14187 non-null  float64\n",
      " 38  host_acceptance_rate                          14187 non-null  float64\n",
      " 39  host_listings_count                           14187 non-null  float64\n",
      " 40  host_total_listings_count                     14187 non-null  float64\n",
      " 41  accommodates                                  14187 non-null  float64\n",
      " 42  bathrooms                                     14187 non-null  float64\n",
      " 43  bedrooms                                      14187 non-null  float64\n",
      " 44  beds                                          14187 non-null  float64\n",
      " 45  price                                         14187 non-null  float64\n",
      " 46  minimum_nights                                14187 non-null  float64\n",
      " 47  maximum_nights                                14187 non-null  float64\n",
      " 48  minimum_minimum_nights                        14187 non-null  float64\n",
      " 49  maximum_minimum_nights                        14187 non-null  float64\n",
      " 50  minimum_maximum_nights                        14187 non-null  float64\n",
      " 51  maximum_maximum_nights                        14187 non-null  float64\n",
      " 52  minimum_nights_avg_ntm                        14187 non-null  float64\n",
      " 53  maximum_nights_avg_ntm                        14187 non-null  float64\n",
      " 54  availability_30                               14187 non-null  int64  \n",
      " 55  availability_60                               14187 non-null  int64  \n",
      " 56  availability_90                               14187 non-null  int64  \n",
      " 57  availability_365                              14187 non-null  int64  \n",
      " 58  number_of_reviews                             14187 non-null  float64\n",
      " 59  number_of_reviews_ltm                         14187 non-null  float64\n",
      " 60  number_of_reviews_l30d                        14187 non-null  float64\n",
      " 61  availability_eoy                              14187 non-null  int64  \n",
      " 62  number_of_reviews_ly                          14187 non-null  float64\n",
      " 63  estimated_occupancy_l365d                     14187 non-null  int64  \n",
      " 64  estimated_revenue_l365d                       14187 non-null  float64\n",
      " 65  review_scores_rating                          14187 non-null  float64\n",
      " 66  review_scores_accuracy                        14187 non-null  float64\n",
      " 67  review_scores_cleanliness                     14187 non-null  float64\n",
      " 68  review_scores_checkin                         14187 non-null  float64\n",
      " 69  review_scores_communication                   14187 non-null  float64\n",
      " 70  review_scores_location                        14187 non-null  float64\n",
      " 71  review_scores_value                           14187 non-null  float64\n",
      " 72  calculated_host_listings_count                14187 non-null  float64\n",
      " 73  calculated_host_listings_count_entire_homes   14187 non-null  float64\n",
      " 74  calculated_host_listings_count_private_rooms  14187 non-null  float64\n",
      " 75  calculated_host_listings_count_shared_rooms   14187 non-null  float64\n",
      " 76  reviews_per_month                             14187 non-null  float64\n",
      " 77  host_is_superhost_num                         14187 non-null  int64  \n",
      " 78  host_has_profile_pic_num                      14187 non-null  int64  \n",
      " 79  host_identity_verified_num                    14187 non-null  int64  \n",
      " 80  has_availability_num                          14187 non-null  int64  \n",
      " 81  instant_bookable_num                          14187 non-null  int64  \n",
      " 82  host_response_rate_cat                        14187 non-null  object \n",
      " 83  review_scores_rating_cat                      14187 non-null  object \n",
      " 84  availability_365_cat                          14187 non-null  object \n",
      " 85  price_cat                                     14187 non-null  object \n",
      " 86  beds_cat                                      14187 non-null  object \n",
      "dtypes: float64(36), int64(13), object(38)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "Berlin = pd.read_csv('Datasets/Berlin_86.csv')\n",
    "Berlin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e911552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14187.000000\n",
       "mean       138.829426\n",
       "std        107.554381\n",
       "min          5.000000\n",
       "25%         90.000000\n",
       "50%        115.000000\n",
       "75%        173.672536\n",
       "max       3923.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Berlin['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f526595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas\n",
    "Berlin.rename(columns= {\n",
    "    'price': 'price_eur', \n",
    "    'estimated_revenue_l365d': 'estimated_revenue_eur'}\n",
    "    ,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0683d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9009 entries, 0 to 9008\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            9009 non-null   int64  \n",
      " 1   listing_url                                   9009 non-null   object \n",
      " 2   scrape_id                                     9009 non-null   int64  \n",
      " 3   last_scraped                                  9009 non-null   object \n",
      " 4   source                                        9009 non-null   object \n",
      " 5   name                                          9009 non-null   object \n",
      " 6   description                                   9009 non-null   object \n",
      " 7   neighborhood_overview                         9009 non-null   object \n",
      " 8   picture_url                                   9009 non-null   object \n",
      " 9   host_id                                       9009 non-null   int64  \n",
      " 10  host_url                                      9009 non-null   object \n",
      " 11  host_name                                     9009 non-null   object \n",
      " 12  host_since                                    9009 non-null   object \n",
      " 13  host_location                                 9009 non-null   object \n",
      " 14  host_about                                    9009 non-null   object \n",
      " 15  host_response_time                            9009 non-null   object \n",
      " 16  host_response_rate                            9009 non-null   object \n",
      " 17  host_acceptance_rate                          9009 non-null   object \n",
      " 18  host_is_superhost                             9009 non-null   object \n",
      " 19  host_thumbnail_url                            9009 non-null   object \n",
      " 20  host_picture_url                              9009 non-null   object \n",
      " 21  host_neighbourhood                            9009 non-null   object \n",
      " 22  host_listings_count                           9009 non-null   float64\n",
      " 23  host_total_listings_count                     9009 non-null   float64\n",
      " 24  host_verifications                            9009 non-null   object \n",
      " 25  host_has_profile_pic                          9009 non-null   object \n",
      " 26  host_identity_verified                        9009 non-null   object \n",
      " 27  neighbourhood                                 9009 non-null   object \n",
      " 28  neighbourhood_cleansed                        9009 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  9009 non-null   object \n",
      " 30  latitude                                      9009 non-null   float64\n",
      " 31  longitude                                     9009 non-null   float64\n",
      " 32  property_type                                 9009 non-null   object \n",
      " 33  room_type                                     9009 non-null   object \n",
      " 34  accommodates                                  9009 non-null   float64\n",
      " 35  bathrooms                                     9009 non-null   float64\n",
      " 36  bathrooms_text                                9009 non-null   object \n",
      " 37  bedrooms                                      9009 non-null   float64\n",
      " 38  beds                                          9009 non-null   float64\n",
      " 39  amenities                                     9009 non-null   object \n",
      " 40  price                                         9009 non-null   float64\n",
      " 41  minimum_nights                                9009 non-null   float64\n",
      " 42  maximum_nights                                9009 non-null   float64\n",
      " 43  minimum_minimum_nights                        9009 non-null   float64\n",
      " 44  maximum_minimum_nights                        9009 non-null   float64\n",
      " 45  minimum_maximum_nights                        9009 non-null   int64  \n",
      " 46  maximum_maximum_nights                        9009 non-null   int64  \n",
      " 47  minimum_nights_avg_ntm                        9009 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        9009 non-null   float64\n",
      " 49  calendar_updated                              9009 non-null   object \n",
      " 50  has_availability                              9009 non-null   object \n",
      " 51  availability_30                               9009 non-null   int64  \n",
      " 52  availability_60                               9009 non-null   int64  \n",
      " 53  availability_90                               9009 non-null   int64  \n",
      " 54  availability_365                              9009 non-null   int64  \n",
      " 55  calendar_last_scraped                         9009 non-null   object \n",
      " 56  number_of_reviews                             9009 non-null   float64\n",
      " 57  number_of_reviews_ltm                         9009 non-null   float64\n",
      " 58  number_of_reviews_l30d                        9009 non-null   float64\n",
      " 59  availability_eoy                              9009 non-null   int64  \n",
      " 60  number_of_reviews_ly                          9009 non-null   float64\n",
      " 61  estimated_occupancy_l365d                     9009 non-null   int64  \n",
      " 62  estimated_revenue_l365d                       9009 non-null   float64\n",
      " 63  first_review                                  9009 non-null   object \n",
      " 64  last_review                                   9009 non-null   object \n",
      " 65  review_scores_rating                          9009 non-null   float64\n",
      " 66  review_scores_accuracy                        9009 non-null   float64\n",
      " 67  review_scores_cleanliness                     9009 non-null   float64\n",
      " 68  review_scores_checkin                         9009 non-null   float64\n",
      " 69  review_scores_communication                   9009 non-null   float64\n",
      " 70  review_scores_location                        9009 non-null   float64\n",
      " 71  review_scores_value                           9009 non-null   float64\n",
      " 72  license                                       9009 non-null   object \n",
      " 73  instant_bookable                              9009 non-null   object \n",
      " 74  calculated_host_listings_count                9009 non-null   float64\n",
      " 75  calculated_host_listings_count_entire_homes   9009 non-null   float64\n",
      " 76  calculated_host_listings_count_private_rooms  9009 non-null   float64\n",
      " 77  calculated_host_listings_count_shared_rooms   9009 non-null   float64\n",
      " 78  reviews_per_month                             9009 non-null   float64\n",
      "dtypes: float64(32), int64(11), object(36)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "Valencia = pd.read_csv('Datasets/valencia_trabajo.csv')\n",
    "Valencia.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbb80d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9009.000000\n",
       "mean      101.443613\n",
       "std        44.644134\n",
       "min         8.000000\n",
       "25%        72.000000\n",
       "50%       101.443613\n",
       "75%       125.000000\n",
       "max       234.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Valencia['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcf5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valencia.rename(columns= {'price':'price_eur', 'estimated_revenue_l365d':'estimated_revenue_eur'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7256a59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_cat\n",
       "Low price     6725\n",
       "High price    2284\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price_cat\n",
    "umbral_precio_Valencia = Valencia['price_eur'].quantile(0.75)\n",
    "Valencia['price_cat'] = np.where(Valencia['price_eur'] >= umbral_precio_Valencia, 'High price', 'Low price')\n",
    "Valencia['price_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea30b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estocolmo.to_csv('Estocolmo_Final.csv')\n",
    "#Mexico.to_csv('Mexico_Final.csv')\n",
    "#Berlin.to_csv('Berlin_Final.csv')\n",
    "#Valencia.to_csv('Valencia_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfb305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dashboard_P1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dashboard_P1.py\n",
    "# Dashboard Final equipo — Proyecto Airbnb (By Raymundo Díaz + IA + Profe Freddy)\n",
    "# Versión de prueba para dejar listos a los 4 países.\n",
    "\n",
    "##########\n",
    "# Importar librerías\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, roc_auc_score, roc_curve, classification_report, f1_score,\n",
    "    precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "##########\n",
    "# Configuración global\n",
    "st.set_page_config(\n",
    "    page_title=\"Airbnb (Data Web)\",\n",
    "    page_icon=\"assets/icon.jpg\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Paleta Airbnb\n",
    "AIRBNB_RED   = \"#FF5A5F\"\n",
    "AIRBNB_TEAL  = \"#00A699\"\n",
    "AIRBNB_ORANGE= \"#FC642D\"\n",
    "AIRBNB_GRAY  = \"#BFBFBF\"\n",
    "AIRBNB_DARK_BG = \"#0E1117\"\n",
    "AIRBNB_CARD   = \"#151A22\"\n",
    "AIRBNB_BORDER = \"#232A35\"\n",
    "CONT_GRADIENT = \"Reds\"\n",
    "\n",
    "##########\n",
    "# CSS Look & Feel Airbnb\n",
    "st.markdown(f\"\"\"\n",
    "<style>\n",
    ".block-container {{ padding-top: 1.2rem; padding-bottom: 2rem; }}\n",
    "\n",
    "/* Fondo degradado unificado */\n",
    "html, body, [data-testid=\"stAppViewContainer\"], section[data-testid=\"stSidebar\"] {{\n",
    "    background: radial-gradient(circle at 30% 30%, #131722 0%, #0E1117 100%) !important;\n",
    "    color: white !important;\n",
    "}}\n",
    "section[data-testid=\"stSidebar\"] {{\n",
    "    border-right: 1px solid {AIRBNB_BORDER};\n",
    "}}\n",
    "\n",
    "/* Tarjetas KPI */\n",
    ".air-card {{\n",
    "    border: 1px solid {AIRBNB_BORDER};\n",
    "    border-radius:16px; padding:1rem;\n",
    "    background:{AIRBNB_CARD};\n",
    "}}\n",
    "\n",
    "/* Botones */\n",
    ".stButton>button {{\n",
    "    background:{AIRBNB_RED}; color:white; border-radius:12px; border:none;\n",
    "    padding:.6rem 1rem; font-weight:600;\n",
    "}}\n",
    ".stButton>button:hover {{ opacity:.9 }}\n",
    "\n",
    "/* Tablas */\n",
    ".stDataFrame, .stTable {{ color: white !important; }}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Plotly: plantilla Airbnb\n",
    "AIRBNB_COLORWAY = [\"#FF5A5F\", \"#00A699\", \"#FC642D\", \"#BFBFBF\", \"#767676\"]\n",
    "pio.templates[\"airbnb_dark\"] = pio.templates[\"plotly_dark\"]\n",
    "pio.templates[\"airbnb_dark\"].layout.colorway = AIRBNB_COLORWAY\n",
    "px.defaults.template = \"airbnb_dark\"\n",
    "px.defaults.color_continuous_scale = CONT_GRADIENT\n",
    "px.defaults.height = 420\n",
    "\n",
    "##########\n",
    "# Multi-país\n",
    "COUNTRY_FILES = {\n",
    "    \"Alemania\": \"Berlin_Final.csv\",\n",
    "    \"Valencia\": \"Valencia_Final.csv\",\n",
    "    \"Estocolmo\": \"Estocolmo_Final.csv\",\n",
    "    \"Mexico\": \"Mexico_Final.csv\",\n",
    "}\n",
    "\n",
    "COUNTRY_IMAGES = {\n",
    "    \"Alemania\": [\"assets/Berlin1.jpg\", \"assets/Berlin3.jpg\", \"assets/Berlin2.jpg\"],\n",
    "    \"Valencia\": [\"assets/Valencia1.jpg\", \"assets/Valencia2.jpg\", \"assets/Valencia3.jpg\"],\n",
    "    \"Estocolmo\": [\"assets/Estocolmo1.jpg\", \"assets/Estocolmo2.jpg\", \"assets/Estocolmo3.jpg\"],\n",
    "    \"Mexico\": [\"assets/Mexico1.jpg\", \"assets/Mexico2.jpg\", \"assets/Mexico3.jpg\"],\n",
    "}\n",
    "\n",
    "##########\n",
    "# Normalización\n",
    "BIN_TRUE = {\"t\",\"true\",\"True\",1,\"1\",True}\n",
    "BIN_FALSE= {\"f\",\"false\",\"False\",0,\"0\",False}\n",
    "\n",
    "def _normalize_binary(series):\n",
    "    s = series.copy()\n",
    "    return s.apply(lambda v: 1 if v in BIN_TRUE else (0 if v in BIN_FALSE else np.nan)).astype(\"float\")\n",
    "\n",
    "def _normalize_df(df_raw):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # 1) Normaliza nombres de columnas (quitan espacios accidentales)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # 2) Drop de *cualquier* columna Unnamed\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\", na=False)]\n",
    "\n",
    "    # 3) Drops opcionales que ya tenías\n",
    "    df = df.drop(['latitude','longitude','first_review','last_review','host_since', 'price', 'estimated_revenue_l365d','source','id', 'scrape_id'],\n",
    "                 axis=1, errors=\"ignore\")\n",
    "\n",
    "    # 4) Tipos\n",
    "    if 'id' in df.columns:\n",
    "        df['id'] = df['id'].astype(str)\n",
    "\n",
    "    if 'host_id' in df.columns:\n",
    "        df['host_id'] = df['host_id'].astype(str)\n",
    "\n",
    "    # 5) Normaliza binarias\n",
    "    for col in ['host_is_superhost','host_identity_verified','instant_bookable']:\n",
    "        if col in df.columns:\n",
    "            df[col] = _normalize_binary(df[col])\n",
    "\n",
    "    # 6) A numérico (coerce => NaN si hay “90%”, etc.)\n",
    "    for col in ['host_response_rate','host_acceptance_rate','price','estimated_revenue_l365d']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "def _clean_xy(df_base, y_col, x_cols):\n",
    "    \"\"\"\n",
    "    Devuelve X, y sin NaN/Inf y un conteo de filas filtradas.\n",
    "    \"\"\"\n",
    "    work = df_base[x_cols + [y_col]].replace([np.inf, -np.inf], np.nan)\n",
    "    before = len(work)\n",
    "    work = work.dropna()\n",
    "    after = len(work)\n",
    "    X = work[x_cols].to_numpy(dtype=float)\n",
    "    y = work[y_col].to_numpy(dtype=float)\n",
    "    return X, y, before - after\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_country_df(country: str):\n",
    "    path = COUNTRY_FILES[country]\n",
    "    raw = pd.read_csv(path)\n",
    "    df = _normalize_df(raw)\n",
    "    Lista = [\n",
    "        'host_is_superhost','host_identity_verified','host_response_time',\n",
    "        'host_response_rate','host_acceptance_rate','host_total_listings_count',\n",
    "        'host_verifications','room_type','property_type','price_cat'\n",
    "    ]\n",
    "    return df, Lista\n",
    "\n",
    "# Carga inicial\n",
    "df, Lista = load_country_df(\"Alemania\")\n",
    "\n",
    "##########\n",
    "# Header\n",
    "col_logo, col_title = st.columns([1,5], vertical_alignment=\"center\")\n",
    "with col_logo:\n",
    "    st.image(\"assets/Logo3.jpg\", width=90)\n",
    "with col_title:\n",
    "    st.markdown(\"\"\"\n",
    "        # Airbnb Data Analysis\n",
    "        <span style=\"color:#767676\">Listados, precios y comportamiento de oferta</span>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Sidebar\n",
    "st.sidebar.image(\"assets/Logoo.jpg\", use_container_width=True)\n",
    "st.sidebar.caption(\"Análisis exploratorio y modelos\")\n",
    "st.sidebar.markdown(\"---\")\n",
    "modo_presentacion = st.sidebar.toggle(\"Modo presentación\", value=False)\n",
    "country = st.sidebar.selectbox(\"País\", list(COUNTRY_FILES.keys()), index=0)\n",
    "df, Lista = load_country_df(country)\n",
    "View = st.sidebar.selectbox(\n",
    "    label='Tipo de análisis',\n",
    "    options=['Extracción de Características', 'Regresión Lineal', 'Regresión No Lineal', 'Regresión Logística', 'Comparar países'],\n",
    "    index=0\n",
    ")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 1 — Extracción de características\n",
    "if View == \"Extracción de Características\":\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Filas\", f\"{len(df):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col2:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Tipos de propiedad\", df['property_type'].nunique() if 'property_type' in df.columns else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        med_price = np.nanmean(df['price_eur']) if 'price_eur' in df.columns else np.nan\n",
    "        st.metric(\"Media de precio\", f\"€{med_price:,.0f}\" if np.isfinite(med_price) else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col4:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        superhosts = int((df['host_is_superhost'] == 1).sum()) if 'host_is_superhost' in df.columns else 0\n",
    "        st.metric(\"Superhosts\", superhosts)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    Variable_Cat = st.sidebar.selectbox(\"Variable categórica a analizar\", options=Lista)\n",
    "    Tabla_frecuencias = df[Variable_Cat].value_counts(dropna=False).reset_index().head(10)\n",
    "    Tabla_frecuencias.columns = ['categorias', 'frecuencia']\n",
    "\n",
    "    st.title(\"Extracción de Características\")\n",
    "    st.caption('Se muestran máximo las 10 categorías con más frecuencia.')\n",
    "\n",
    "    Contenedor_A, Contenedor_B = st.columns(2)\n",
    "    with Contenedor_A:\n",
    "        st.subheader(\"Distribución por categoría (Bar Plot)\")\n",
    "        fig_bar = px.bar(Tabla_frecuencias, x='categorias', y='frecuencia', color='categorias')\n",
    "        st.plotly_chart(fig_bar, use_container_width=True)\n",
    "    with Contenedor_B:\n",
    "        st.subheader(\"Proporción por categoría (Pie Chart)\")\n",
    "        fig_pie = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia')\n",
    "        st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "    Contenedor_C, Contenedor_D = st.columns(2)\n",
    "    with Contenedor_C:\n",
    "        st.subheader(\"Gráfico tipo anillo\")\n",
    "        fig_donut = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia', hole=0.5)\n",
    "        st.plotly_chart(fig_donut, use_container_width=True)\n",
    "    with Contenedor_D:\n",
    "        st.subheader(\"Tendencia acumulada (Área)\")\n",
    "        fig_area = px.area(Tabla_frecuencias.sort_values(by='frecuencia', ascending=False),\n",
    "                           x='categorias', y='frecuencia')\n",
    "        st.plotly_chart(fig_area, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Análisis más profundo\")\n",
    "\n",
    "    if Variable_Cat in ['room_type', 'property_type', 'price_cat'] and 'price' in df.columns:\n",
    "        st.write(\"**Relación entre categorías y precio (Boxplot):**\")\n",
    "        fig_box = px.box(df, x=Variable_Cat, y='price', color=Variable_Cat)\n",
    "        st.plotly_chart(fig_box, use_container_width=True)\n",
    "    else:\n",
    "        st.write(\"**Heatmap de proporciones:**\")\n",
    "        heat_df = pd.crosstab(index=df[Variable_Cat], columns='count', normalize='columns') * 100\n",
    "        fig_heat = px.imshow(heat_df, color_continuous_scale=CONT_GRADIENT, title=\"Proporción por categoría\")\n",
    "        st.plotly_chart(fig_heat, use_container_width=True)\n",
    "\n",
    "    if not modo_presentacion:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Tabla de frecuencias\")\n",
    "        st.dataframe(Tabla_frecuencias.style.background_gradient(cmap='Reds'), use_container_width=True)\n",
    "\n",
    "    st.markdown(f\"**Galería:** {country} — Airbnb\")\n",
    "    imgs = COUNTRY_IMAGES.get(country, [])\n",
    "    gcols = st.columns(3)\n",
    "    for i, path in enumerate(imgs[:3]):\n",
    "        with gcols[i]:\n",
    "            try:\n",
    "                st.image(path, use_container_width=True)\n",
    "            except Exception:\n",
    "                st.write(\"🖼️ Imagen no encontrada\")\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 2 \n",
    "if View == \"Regresión Lineal\":\n",
    "    st.title(\"Regresión Lineal\")\n",
    "\n",
    "    # Variables numéricas disponibles\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    # Lineal simple\n",
    "    st.subheader(\"Regresión lineal simple\")\n",
    "    colL, colR = st.columns(2)\n",
    "    with colL:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rl_y\")\n",
    "    with colR:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=Lista_num, key=\"rl_x\")\n",
    "\n",
    "    # Ajuste\n",
    "    X, y, dropped = _clean_xy(numeric_df, Variable_y, [Variable_x])\n",
    "    if dropped > 0 and not modo_presentacion:\n",
    "        st.info(f\"Se descartaron {dropped} filas con NaN/Inf para el ajuste.\")\n",
    "\n",
    "    if len(y) < 3:\n",
    "        st.error(\"No hay suficientes filas válidas para ajustar el modelo.\")\n",
    "        st.stop()\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "\n",
    "    # Métricas\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    coef_Deter_simple = model.score(X= X, y= y)\n",
    "    coef_Correl_simple = np.sqrt(abs(coef_Deter_simple))\n",
    "\n",
    "    # Coeficientes\n",
    "    coef_df_simple = pd.DataFrame({\n",
    "        \"Variable\": [Variable_x],\n",
    "        \"Coeficiente\": [model.coef_[0]],\n",
    "        \"Intercepto\": [model.intercept_],\n",
    "        \"R\": [coef_Correl_simple],\n",
    "        \"R^2\": [coef_Deter_simple]\n",
    "    })\n",
    "\n",
    "    if not modo_presentacion:\n",
    "        st.dataframe(coef_df_simple, use_container_width=True)\n",
    "\n",
    "    # Gráfica: dispersión + recta y_pred\n",
    "    fig_scat = px.scatter(numeric_df, x=Variable_x, y=Variable_y, opacity=0.6, title=\"Dispersión y recta ajustada\")\n",
    "    # Línea predicha ordenando por X\n",
    "    order_idx = np.argsort(X[:, 0])\n",
    "    fig_scat.add_trace(go.Scatter(\n",
    "        x=X[order_idx, 0], y=y_pred[order_idx],\n",
    "        mode=\"lines\", name=\"Predicción de Y\"\n",
    "    ))\n",
    "    st.plotly_chart(fig_scat, use_container_width=True)\n",
    "\n",
    "    # Residuales\n",
    "    resid = y - y_pred\n",
    "    fig_res = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"},\n",
    "                         title=\"Residuos vs Predicción (diagnóstico)\")\n",
    "    fig_res.add_hline(y=0, line_dash=\"dot\")\n",
    "    st.plotly_chart(fig_res, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Lineal múltiple\n",
    "    st.subheader(\"Regresión lineal múltiple\")\n",
    "    col1, col2 = st.columns([1,2])\n",
    "    with col1:\n",
    "        Variable_y_M = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rlm_y\")\n",
    "    with col2:\n",
    "        Variables_x_M = st.multiselect(\"Variables independientes (X)\", options= Lista_num, key=\"rlm_xs\")\n",
    "\n",
    "    if len(Variables_x_M) >= 1:\n",
    "        X_M, y_M, droppedM = _clean_xy(numeric_df, Variable_y_M, Variables_x_M)\n",
    "        if droppedM > 0 and not modo_presentacion:\n",
    "            st.info(f\"Se descartaron {droppedM} filas con NaN/Inf para el ajuste múltiple.\")\n",
    "        if len(y_M) < max(3, len(Variables_x_M)+1):\n",
    "            st.error(\"No hay suficientes filas válidas para el modelo múltiple.\")\n",
    "            st.stop()\n",
    "\n",
    "        Model_M = LinearRegression()\n",
    "        Model_M.fit(X_M, y_M)\n",
    "        y_pred_M = Model_M.predict(X_M)\n",
    "\n",
    "        # Métricas\n",
    "        coef_Deter_multiple = Model_M.score(X=X_M, y=y_M)\n",
    "        coef_Correl_multiple = np.sqrt(abs(coef_Deter_multiple))\n",
    "\n",
    "        # Coeficientes\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x_M,\n",
    "            \"Coeficiente\": [Model_M.intercept_] + list(Model_M.coef_)\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        met_tab = pd.DataFrame({'R^2': [coef_Deter_multiple], 'R ': [coef_Correl_multiple]})\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        # Gráfica: Real vs Predicho\n",
    "        fig_pred = px.scatter(x=y_M, y=y_pred_M, labels={\"x\":\"Y real \", \"y\": \"Y predicciones\"}, title=\"Comparación Y Real vs Y Predicciones\")\n",
    "        fig_pred.add_trace(go.Scatter(x=[y_M.min(), y_M.max()], y=[y_M.min(), y_M.max()], mode=\"lines\", name=\"Línea ideal\", line=dict(dash=\"dot\")))\n",
    "        st.plotly_chart(fig_pred, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Selecciona al menos 1 variable para el modelo múltiple.\")\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 3\n",
    "if View == \"Regresión No Lineal\":\n",
    "    st.title(\"Regresión No Lineal\")\n",
    "\n",
    "    # Variables numéricas\n",
    "    numeric_df = df.select_dtypes(include=['float','float64','int','int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    contA, contB = st.columns(2)\n",
    "    with contA:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rnl_y_cf\")\n",
    "    with contB:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=[c for c in Lista_num if c != Variable_y], key=\"rnl_x_cf\")\n",
    "\n",
    "    # Modelos disponibles\n",
    "    modelos = [\n",
    "        \"Función cuadrática (a*x**2 + b*x + c)\",\n",
    "        \"Función exponencial (a*np.exp(-b*x)+c)\",\n",
    "        \"Función potencia (a*x**b)\",\n",
    "        \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\"\n",
    "    ]\n",
    "    Modelo = st.selectbox(\"Elige modelo no lineal\", options=modelos, key=\"rnl_modelo_cf\")\n",
    "\n",
    "    # Datos\n",
    "    df_nl = numeric_df[[Variable_x, Variable_y]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(df_nl) < 3:\n",
    "        st.error(\"Datos insuficientes tras limpiar NaN/Inf para ajustar el modelo no lineal.\")\n",
    "        st.stop()\n",
    "\n",
    "    x = df_nl[Variable_x].to_numpy(dtype=float)\n",
    "    y = df_nl[Variable_y].to_numpy(dtype=float)\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "\n",
    "\n",
    "    # Definiciones de funciones\n",
    "    def func_cuad(x, a, b, c):\n",
    "        return a*x**2 + b*x + c\n",
    "\n",
    "    def func_cub(x, a, b, c, d):\n",
    "        return a*x**3 + b*x**2 + c*x + d\n",
    "\n",
    "    def func_exp(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "\n",
    "    def func_pot(x, a, b):\n",
    "        return a * np.power(x, b)\n",
    "\n",
    "    # Ajuste\n",
    "    try:\n",
    "        if Modelo == \"Función cuadrática (a*x**2 + b*x + c)\":\n",
    "            pars, cov = curve_fit(func_cuad, x, y, maxfev=20000)\n",
    "            y_pred = func_cuad(x, *pars)\n",
    "            y_line = func_cuad(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "\n",
    "        elif Modelo == \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\":\n",
    "            pars, cov = curve_fit(func_cub, x, y, maxfev=30000)\n",
    "            y_pred = func_cub(x, *pars)\n",
    "            y_line = func_cub(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\", \"d\"], \"Valor\": pars})\n",
    "\n",
    "        elif Modelo == \"Función exponencial (a*np.exp(-b*x)+c)\":\n",
    "            mask = np.isfinite(y)\n",
    "            if np.sum(mask) < 3:\n",
    "                st.error(\"No hay suficientes datos válidos para ajustar el modelo exponencial.\")\n",
    "                st.stop()\n",
    "            pars, cov = curve_fit(func_exp, x, y, maxfev=30000)\n",
    "            y_pred = func_exp(x, *pars)\n",
    "            y_line = func_exp(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "\n",
    "        elif Modelo == \"Función potencia (a*x**b)\":\n",
    "            # Requiere x>0 y y>0\n",
    "            mask = (x > 0) & (y > 0) & np.isfinite(x) & np.isfinite(y)\n",
    "            if mask.sum() < 3:\n",
    "                st.error(\"Para la función potencia se requieren suficientes valores con x>0 e y>0.\")\n",
    "                st.stop()\n",
    "            x_pos, y_pos = x[mask], y[mask]\n",
    "            pars, cov = curve_fit(func_pot, x_pos, y_pos, maxfev=20000)\n",
    "            # Predicciones seguras en todo el rango\n",
    "            x_safe = np.clip(x, 1e-12, None)\n",
    "            x_sorted_safe = np.clip(x_sorted, 1e-12, None)\n",
    "            y_pred = func_pot(x_safe, *pars)\n",
    "            y_line = func_pot(x_sorted_safe, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\"], \"Valor\": pars})\n",
    "\n",
    "        else:\n",
    "            st.warning(\"Selecciona un modelo válido.\")\n",
    "            st.stop()\n",
    "\n",
    "        # Métricas\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        r = np.sqrt(abs(r2))\n",
    "\n",
    "        # Salidas\n",
    "        st.markdown(\"**Parámetros estimados (curve_fit):**\")\n",
    "        if not modo_presentacion:\n",
    "            st.dataframe(params_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"**Métricas del ajuste:**\")\n",
    "        st.dataframe(pd.DataFrame({\"R^2\":[r2], \"R \":[r]}), use_container_width=True)\n",
    "\n",
    "        # Gráfica: dispersión + curva predicha\n",
    "        fig = px.scatter(x=x, y=y, labels={\"x\": Variable_x, \"y\": Variable_y},\n",
    "                         opacity=0.6, title=f\"{Modelo} — Dispersión y curva ajustada\")\n",
    "        fig.add_trace(go.Scatter(x=x_sorted, y=y_line, mode=\"lines\", name=\"Ŷ (curva)\", line=dict(width=2)))\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # Residuos\n",
    "        resid = y - y_pred\n",
    "        fig_resid = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"},\n",
    "                               title=\"Residuos vs Predicción\")\n",
    "        fig_resid.add_hline(y=0, line_dash=\"dot\")\n",
    "        st.plotly_chart(fig_resid, use_container_width=True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        st.error(f\"No convergió el ajuste: {e}. Prueba con otra X/Y o revisa outliers.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error durante el ajuste: {e}\")\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 4\n",
    "if View == \"Regresión Logística\":\n",
    "    st.title(\"Regresión Logística\")\n",
    "\n",
    "    # 1) Listas base: Y binaria y X numéricas\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64'])\n",
    "    Lista_num  = list(numeric_df.columns)\n",
    "\n",
    "    # Detectar dicotómicas (exactamente 2 valores distintos, ignorando NaN)\n",
    "    dico_cols = []\n",
    "    for col in df.columns:\n",
    "        vals = df[col].dropna().unique()\n",
    "        if len(vals) == 2:\n",
    "            dico_cols.append(col)\n",
    "\n",
    "    # Sidebar\n",
    "    if len(dico_cols) == 0:\n",
    "        st.warning(\"No se detectaron variables binarias en el dataset.\")\n",
    "        st.stop()\n",
    "\n",
    "    Variable_y = st.sidebar.selectbox(\"Variable dependiente (Y, binaria)\", options=dico_cols)\n",
    "    Variables_x = st.sidebar.multiselect(\"Variables independientes (X, numéricas)\", options=Lista_num)\n",
    "\n",
    "    # Sliders\n",
    "    test_size = st.sidebar.slider(\"Tamaño de prueba\", 0.1, 0.5, 0.30, 0.05)\n",
    "    thr = st.sidebar.slider(\"Umbral de clasificación\", 0.05, 0.95, 0.50, 0.01)\n",
    "\n",
    "    if len(Variables_x) == 0:\n",
    "        st.info(\"Selecciona al menos una variable independiente (X).\")\n",
    "    else:\n",
    "        # 2) Preparar X, y (sin modificar df original)\n",
    "        # Trabajar sobre un df que contenga todas las columnas necesarias\n",
    "        base = df[Variables_x + [Variable_y]].copy()\n",
    "\n",
    "        # Mapear Y a {0,1} conservando nombres\n",
    "        vals = base[Variable_y].dropna().unique().tolist()\n",
    "        if len(vals) != 2:\n",
    "            st.error(f\"La variable '{Variable_y}' debe tener exactamente 2 clases. Encontradas: {vals}\")\n",
    "            st.stop()\n",
    "\n",
    "        mapping = {vals[0]: 0, vals[1]: 1}\n",
    "        base['__y__'] = base[Variable_y].map(mapping)\n",
    "\n",
    "        # Quita NaN/Inf en X y NaN en Y\n",
    "        base = base.replace([np.inf, -np.inf], np.nan).dropna(subset=Variables_x + ['__y__'])\n",
    "\n",
    "        if base['__y__'].nunique() < 2:\n",
    "            st.error(\"Tras limpiar datos, solo queda una clase en Y. Ajusta la selección de variables o revisa faltantes.\")\n",
    "            st.stop()\n",
    "\n",
    "        X = base[Variables_x].astype(float).to_numpy()\n",
    "        y = base['__y__'].to_numpy(dtype=int)\n",
    "        clases = vals  # para etiquetar métricas\n",
    "\n",
    "        # 3) Split + escalado        \n",
    "        # Sidebar extra: manejo de desbalance y estrategia de umbral\n",
    "        st.sidebar.markdown(\"### Manejo de desbalance\")\n",
    "        imb_method = st.sidebar.selectbox(\"Método\", [\"Ninguno\",\n",
    "                                                    \"class_weight='balanced'\",\n",
    "                                                    \"SMOTE (over-sampling)\",\n",
    "                                                    \"Under-sampling\"])\n",
    "\n",
    "        st.sidebar.markdown(\"### Estrategia de umbral\")\n",
    "        thr_mode = st.sidebar.selectbox(\"Seleccionar umbral por…\",\n",
    "                                        [\"Manual\", \"F1 óptimo\", \"Minimizar costo\", \"Maximizar recall con precisión mínima\"])\n",
    "        prec_min = None\n",
    "        c_fp = None\n",
    "        c_fn = None\n",
    "        if thr_mode == \"Manual\":\n",
    "            thr = st.sidebar.slider(\"Umbral de clasificación\", 0.01, 0.99, thr, 0.01)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            prec_min = st.sidebar.slider(\"Precisión mínima requerida\", 0.1, 0.99, 0.6, 0.01)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            # Ajusta estos valores a tu caso: p. ej., FP=10,000; FN=80,000 (como has usado antes)\n",
    "            c_fp = st.sidebar.number_input(\"Costo por FP\", min_value=0, value=10000, step=1000)\n",
    "            c_fn = st.sidebar.number_input(\"Costo por FN\", min_value=0, value=80000, step=1000)\n",
    "\n",
    "        # 3) Split + escalado\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        escalar = StandardScaler()\n",
    "        X_train_s = escalar.fit_transform(X_train)\n",
    "        X_test_s  = escalar.transform(X_test)\n",
    "\n",
    "        # 3.1) Re-muestreo (solo sobre el set de entrenamiento ya escalado)\n",
    "        if imb_method == \"SMOTE (over-sampling)\":\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train_s, y_train = sm.fit_resample(X_train_s, y_train)\n",
    "        elif imb_method == \"Under-sampling\":\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train_s, y_train = rus.fit_resample(X_train_s, y_train)\n",
    "\n",
    "        # 4) Modelo (class_weight según selección)\n",
    "        if imb_method == \"class_weight='balanced'\":\n",
    "            algoritmo = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        else:\n",
    "            algoritmo = LogisticRegression(max_iter=1000)\n",
    "\n",
    "        algoritmo.fit(X_train_s, y_train)\n",
    "\n",
    "        # 5) Probabilidades y selección de umbral\n",
    "        y_proba = algoritmo.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "        def pick_threshold_by_f1(y_true, y_score):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            f1 = 2 * (p*r) / np.clip(p+r, 1e-12, None)\n",
    "            # precision_recall_curve devuelve umbrales len-1 respecto a p/r\n",
    "            best_idx = np.nanargmax(f1[:-1])\n",
    "            return th[best_idx], f1[best_idx], p[best_idx], r[best_idx]\n",
    "\n",
    "        def pick_threshold_by_cost(y_true, y_score, c_fp, c_fn):\n",
    "            # Recorremos 1001 umbrales uniformes\n",
    "            ths = np.linspace(0.0, 1.0, 1001)\n",
    "            best_th, best_cost = 0.5, np.inf\n",
    "            for t in ths:\n",
    "                y_pred = (y_score >= t).astype(int)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "                cost = fp * c_fp + fn * c_fn\n",
    "                if cost < best_cost:\n",
    "                    best_cost, best_th = cost, t\n",
    "            return best_th, best_cost\n",
    "\n",
    "        def pick_threshold_by_recall_with_prec_min(y_true, y_score, prec_min=0.6):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            # p/r len N, th len N-1. Usamos índices de th.\n",
    "            valid = np.where(p[:-1] >= prec_min)[0]\n",
    "            if len(valid) == 0:\n",
    "                return 0.5, 0.0, 0.0  # fallback\n",
    "            # entre los que cumplen precisión mínima, elegimos el de mayor recall\n",
    "            best_idx = valid[np.argmax(r[valid])]\n",
    "            return th[best_idx], r[best_idx], p[best_idx]\n",
    "\n",
    "        # Elegimos umbral según estrategia\n",
    "        if thr_mode == \"F1 óptimo\":\n",
    "            thr, best_f1, best_p, best_r = pick_threshold_by_f1(y_test, y_proba)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            thr, best_cost = pick_threshold_by_cost(y_test, y_proba, c_fp, c_fn)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            thr, best_r, best_p = pick_threshold_by_recall_with_prec_min(y_test, y_proba, prec_min=prec_min)\n",
    "        # Si es \"Manual\", ya viene de la sidebar\n",
    "\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "        # 6) Métricas ampliadas\n",
    "        acc     = accuracy_score(y_test, y_pred)\n",
    "        bacc    = balanced_accuracy_score(y_test, y_pred)\n",
    "        prec_c0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        prec_c1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        rec_c0  = recall_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        rec_c1  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        f1_min  = f1_score(y_test, y_pred, pos_label=1, zero_division=0)  # F1 de la minoritaria (etiqueta 1)\n",
    "        auc     = roc_auc_score(y_test, y_proba)\n",
    "        auprc   = average_precision_score(y_test, y_proba)  # área bajo curva Prec-Recall (clase 1)\n",
    "\n",
    "        # Tabla de métricas\n",
    "        met_rows = [\n",
    "            (\"Exactitud\", acc),\n",
    "            (\"Balanced accuracy\", bacc),\n",
    "            (f\"Precision ({clases[0]})\", prec_c0),\n",
    "            (f\"Precision ({clases[1]})\", prec_c1),\n",
    "            (f\"Sensibilidad ({clases[0]})\", rec_c0),\n",
    "            (f\"Sensibilidad ({clases[1]})\", rec_c1),\n",
    "            (f\"F1 ({clases[1]})\", f1_min),\n",
    "            (\"ROC-AUC\", auc)\n",
    "        ]\n",
    "        if thr_mode == \"Minimizar costo\":\n",
    "            met_rows.append((\"Costo total (FP/FN)\", best_cost))\n",
    "\n",
    "        met_tab = pd.DataFrame(met_rows, columns=[\"Métrica\", \"Valor\"])\n",
    "        st.subheader(\"Métricas\")\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        # Alertas útiles\n",
    "        prev = y_test.mean()\n",
    "        if prec_c1 == 1.0 and rec_c1 < 0.15:\n",
    "            st.warning(\"La precisión de la clase minoritaria es 1.0 pero el recall es muy bajo. \"\n",
    "                    \"Baja el umbral, usa class_weight='balanced' o aplica re-muestreo.\")\n",
    "        if acc > 0.9 and bacc < 0.65 and prev < 0.25:\n",
    "            st.info(\"La exactitud es alta por el desbalance. Revisa balanced accuracy, AUPRC y F1 de la minoritaria.\")\n",
    "\n",
    "        # 7) Coeficientes y Odds Ratios (sin cambios)\n",
    "        coef = algoritmo.coef_[0]\n",
    "        intercepto = algoritmo.intercept_[0]\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x,\n",
    "            \"Coeficiente (log-odds)\": [intercepto] + list(coef),\n",
    "            \"Odds Ratio (exp(coef))\": [np.exp(intercepto)] + list(np.exp(coef))\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.subheader(\"Coeficientes del modelo\")\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        # 8) Matriz de confusión (igual que ya tenías)\n",
    "        matriz = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        labels_disp = [clases[0], clases[1]]\n",
    "        fig_cm = go.Figure(data=go.Heatmap(\n",
    "            z=matriz,\n",
    "            x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"],\n",
    "            y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"],\n",
    "            colorscale=\"Oranges\", showscale=True, hoverongaps=False\n",
    "        ))\n",
    "        ann = []\n",
    "        tags = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ann.append(dict(\n",
    "                    x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"][j],\n",
    "                    y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"][i],\n",
    "                    text=f\"{tags[i,j]}: {matriz[i,j]}\",\n",
    "                    showarrow=False,\n",
    "                    font=dict(color=\"white\" if matriz[i,j] > matriz.max()/2 else \"black\")\n",
    "                ))\n",
    "        fig_cm.update_layout(title=\"Matriz de confusión\", annotations=ann, width=520, height=520)\n",
    "        st.plotly_chart(fig_cm, use_container_width=False)\n",
    "\n",
    "        # 9) Curva ROC (igual)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        fig_roc = go.Figure()\n",
    "        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={auc:.3f})\"))\n",
    "        fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Aleatorio\", line=dict(dash=\"dot\")))\n",
    "        fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "        st.plotly_chart(fig_roc, use_container_width=True)\n",
    "\n",
    "        # 10) Curva Precisión-Recall y distribución de probabilidades\n",
    "        p, r, th = precision_recall_curve(y_test, y_proba)\n",
    "        fig_pr = go.Figure()\n",
    "        fig_pr.add_trace(go.Scatter(x=r, y=p, mode=\"lines\", name=f\"PR (AP={auprc:.3f})\"))\n",
    "        fig_pr.update_layout(title=\"Curva Precisión-Recall (clase 1)\",\n",
    "                            xaxis_title=\"Recall\", yaxis_title=\"Precisión\")\n",
    "        st.plotly_chart(fig_pr, use_container_width=True)\n",
    "\n",
    "        fig_prob = px.strip(\n",
    "            x=[labels_disp[i] for i in y_test], y=y_proba,\n",
    "            labels={\"x\":\"Clase real\", \"y\":\"Probabilidad P(Y=1)\"},\n",
    "            title=\"Distribución de probabilidades por clase real\"\n",
    "        )\n",
    "        fig_prob.add_hline(y=thr, line_dash=\"dot\", annotation_text=f\"Umbral {thr:.2f}\")\n",
    "        st.plotly_chart(fig_prob, use_container_width=True)\n",
    "\n",
    "        # Nota de mapeo (como ya tenías)\n",
    "        st.caption(f\"Mapeo interno (solo para el modelo): {clases[0]} → 0, {clases[1]} → 1. \"\n",
    "                f\"Prevalencia clase 1 (test): {prev:.3f}\")\n",
    "\n",
    "# FOOTER\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style=\"text-align:center; opacity:0.8; font-size:0.9rem;\">\n",
    "© Proyecto para Gestión de Proyectos — Dashboard creado por <b>Los Guaranies</b> con ayuda de IA y profe Freddy/Malu.  \n",
    "<br> Construido con Streamlit, Plotly y Python.\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4be8cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dashboard_Comparativo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dashboard_Comparativo.py\n",
    "# Dashboard Final equipo integrando en las vistas a los 4 países - Proyecto Airbnb\n",
    "# Versión final\n",
    "\n",
    "##########\n",
    "# Importar librerías\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, roc_auc_score, roc_curve, classification_report, f1_score,\n",
    "    precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "##########\n",
    "# Configuración global\n",
    "st.set_page_config(\n",
    "    page_title=\"Airbnb (Data Web)\",\n",
    "    page_icon=\"assets/icon.jpg\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Paleta Airbnb\n",
    "AIRBNB_RED   = \"#FF5A5F\"\n",
    "AIRBNB_TEAL  = \"#00A699\"\n",
    "AIRBNB_ORANGE= \"#FC642D\"\n",
    "AIRBNB_GRAY  = \"#BFBFBF\"\n",
    "AIRBNB_DARK_BG = \"#0E1117\"\n",
    "AIRBNB_CARD   = \"#151A22\"\n",
    "AIRBNB_BORDER = \"#232A35\"\n",
    "CONT_GRADIENT = \"Reds\"\n",
    "\n",
    "##########\n",
    "# CSS Look & Feel Airbnb\n",
    "st.markdown(f\"\"\"\n",
    "<style>\n",
    ".block-container {{ padding-top: 1.2rem; padding-bottom: 2rem; }}\n",
    "html, body, [data-testid=\"stAppViewContainer\"], section[data-testid=\"stSidebar\"] {{\n",
    "    background: radial-gradient(circle at 30% 30%, #131722 0%, #0E1117 100%) !important;\n",
    "    color: white !important;\n",
    "}}\n",
    "section[data-testid=\"stSidebar\"] {{ border-right: 1px solid {AIRBNB_BORDER}; }}\n",
    ".air-card {{\n",
    "    border: 1px solid {AIRBNB_BORDER};\n",
    "    border-radius:16px; padding:1rem;\n",
    "    background:{AIRBNB_CARD};\n",
    "}}\n",
    ".stButton>button {{\n",
    "    background:{AIRBNB_RED}; color:white; border-radius:12px; border:none;\n",
    "    padding:.6rem 1rem; font-weight:600;\n",
    "}}\n",
    ".stButton>button:hover {{ opacity:.9 }}\n",
    ".stDataFrame, .stTable {{ color: white !important; }}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Plotly: plantilla Airbnb\n",
    "AIRBNB_COLORWAY = [\"#FF5A5F\", \"#00A699\", \"#FC642D\", \"#BFBFBF\", \"#767676\"]\n",
    "pio.templates[\"airbnb_dark\"] = pio.templates[\"plotly_dark\"]\n",
    "pio.templates[\"airbnb_dark\"].layout.colorway = AIRBNB_COLORWAY\n",
    "px.defaults.template = \"airbnb_dark\"\n",
    "px.defaults.color_continuous_scale = CONT_GRADIENT\n",
    "px.defaults.height = 420\n",
    "\n",
    "##########\n",
    "# Multi-país\n",
    "COUNTRY_FILES = {\n",
    "    \"Alemania\": \"Berlin_Final.csv\",\n",
    "    \"Valencia\": \"Valencia_Final.csv\",\n",
    "    \"Estocolmo\": \"Estocolmo_Final.csv\",\n",
    "    \"Mexico\": \"Mexico_Final.csv\",\n",
    "}\n",
    "\n",
    "COUNTRY_IMAGES = {\n",
    "    \"Alemania\": [\"assets/Berlin1.jpg\", \"assets/Berlin3.jpg\", \"assets/Berlin2.jpg\"],\n",
    "    \"Valencia\": [\"assets/Valencia1.jpg\", \"assets/Valencia2.jpg\", \"assets/Valencia3.jpg\"],\n",
    "    \"Estocolmo\": [\"assets/Estocolmo1.jpg\", \"assets/Estocolmo2.jpg\", \"assets/Estocolmo3.jpg\"],\n",
    "    \"Mexico\": [\"assets/Mexico1.jpg\", \"assets/Mexico2.jpg\", \"assets/Mexico3.jpg\"],\n",
    "}\n",
    "\n",
    "##########\n",
    "# Normalización\n",
    "BIN_TRUE = {\"t\",\"true\",\"True\",1,\"1\",True}\n",
    "BIN_FALSE= {\"f\",\"false\",\"False\",0,\"0\",False}\n",
    "\n",
    "def _normalize_binary(series):\n",
    "    s = series.copy()\n",
    "    return s.apply(lambda v: 1 if v in BIN_TRUE else (0 if v in BIN_FALSE else np.nan)).astype(\"float\")\n",
    "\n",
    "def _normalize_df(df_raw):\n",
    "    df = df_raw.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\", na=False)]\n",
    "    df = df.drop(['latitude','longitude','first_review','last_review','host_since', 'price', 'estimated_revenue_l365d','source','id', 'scrape_id'],\n",
    "                 axis=1, errors=\"ignore\")\n",
    "    if 'id' in df.columns:\n",
    "        df['id'] = df['id'].astype(str)\n",
    "    if 'host_id' in df.columns:\n",
    "        df['host_id'] = df['host_id'].astype(str)\n",
    "    for col in ['host_is_superhost','host_identity_verified','instant_bookable']:\n",
    "        if col in df.columns:\n",
    "            df[col] = _normalize_binary(df[col])\n",
    "    for col in ['host_response_rate','host_acceptance_rate','price','estimated_revenue_l365d','price_eur']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def _clean_xy(df_base, y_col, x_cols):\n",
    "    work = df_base[x_cols + [y_col]].replace([np.inf, -np.inf], np.nan)\n",
    "    before = len(work)\n",
    "    work = work.dropna()\n",
    "    after = len(work)\n",
    "    X = work[x_cols].to_numpy(dtype=float)\n",
    "    y = work[y_col].to_numpy(dtype=float)\n",
    "    return X, y, before - after\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_country_df(country: str):\n",
    "    path = COUNTRY_FILES[country]\n",
    "    raw = pd.read_csv(path)\n",
    "    df = _normalize_df(raw)\n",
    "    Lista = [\n",
    "        'host_is_superhost','host_identity_verified','host_response_time',\n",
    "        'host_response_rate','host_acceptance_rate','host_total_listings_count',\n",
    "        'host_verifications','room_type','property_type','price_cat'\n",
    "    ]\n",
    "    return df, Lista\n",
    "\n",
    "def kpis_block(df, country):\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(f\"{country} · Filas\", f\"{len(df):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col2:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(f\"{country} · Tipos de propiedad\", df['property_type'].nunique() if 'property_type' in df.columns else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        med_price = np.nanmean(df['price_eur']) if 'price_eur' in df.columns else np.nan\n",
    "        st.metric(f\"{country} · Media precio\", f\"€{med_price:,.0f}\" if np.isfinite(med_price) else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col4:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        superhosts = int((df['host_is_superhost'] == 1).sum()) if 'host_is_superhost' in df.columns else 0\n",
    "        st.metric(f\"{country} · Superhosts\", superhosts)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def extraction_charts(df, var_cat: str):\n",
    "    tabla = df[var_cat].value_counts(dropna=False).reset_index().head(10)\n",
    "    tabla.columns = ['categorias','frecuencia']\n",
    "    fig_bar = px.bar(tabla, x='categorias', y='frecuencia', color='categorias', title=\"Distribución por categoría\")\n",
    "    fig_pie = px.pie(tabla, names='categorias', values='frecuencia', title=\"Proporción por categoría\")\n",
    "    fig_donut = px.pie(tabla, names='categorias', values='frecuencia', hole=0.5, title=\"Gráfico tipo anillo\")\n",
    "    fig_area = px.area(tabla.sort_values('frecuencia', ascending=False),\n",
    "                       x='categorias', y='frecuencia', title=\"Tendencia acumulada (Área)\")\n",
    "    # Detalle: box/heatmap según exista price\n",
    "    detail_fig = None\n",
    "    if var_cat in ['room_type','property_type','price_cat'] and 'price' in df.columns:\n",
    "        detail_fig = px.box(df, x=var_cat, y='price', color=var_cat, title=\"Relación categorías vs precio (Boxplot)\")\n",
    "    else:\n",
    "        heat_df = pd.crosstab(index=df[var_cat], columns='count', normalize='columns') * 100\n",
    "        detail_fig = px.imshow(heat_df, color_continuous_scale=CONT_GRADIENT, title=\"Proporción por categoría (Heatmap)\")\n",
    "    return tabla, fig_bar, fig_pie, fig_donut, fig_area, detail_fig\n",
    "\n",
    "def gallery_block(country):\n",
    "    st.markdown(f\"**Galería:** {country} — Airbnb\")\n",
    "    imgs = COUNTRY_IMAGES.get(country, [])\n",
    "    gcols = st.columns(3)\n",
    "    for i, path in enumerate(imgs[:3]):\n",
    "        with gcols[i]:\n",
    "            try:\n",
    "                st.image(path, use_container_width=True)\n",
    "            except Exception:\n",
    "                st.write(\"🖼️ Imagen no encontrada\")\n",
    "\n",
    "def get_common_lists(dfs_dict):\n",
    "    # Intersección de columnas numéricas y binarias para logística / extracción\n",
    "    num_sets = []\n",
    "    bin_sets = []\n",
    "    cat_sets = []\n",
    "    for _, df in dfs_dict.items():\n",
    "        num_cols = set(df.select_dtypes(include=['float','float64','int','int64']).columns.tolist())\n",
    "        # binarias: exactamente 2 valores (ignorando NaN)\n",
    "        bin_cols = set([c for c in df.columns if df[c].dropna().nunique()==2])\n",
    "        # categóricas candidatas (object o categóricas + algunas conocidas)\n",
    "        cat_cols = set([c for c in df.columns if df[c].dtype=='object' or df[c].dtype.name=='category'])\n",
    "        # agrega columnas 'conocidas' aunque sean numéricas codificadas\n",
    "        cat_cols |= set([c for c in ['room_type','property_type','price_cat','host_response_time'] if c in df.columns])\n",
    "        num_sets.append(num_cols)\n",
    "        bin_sets.append(bin_cols)\n",
    "        cat_sets.append(cat_cols)\n",
    "    common_num = set.intersection(*num_sets) if num_sets else set()\n",
    "    common_bin = set.intersection(*bin_sets) if bin_sets else set()\n",
    "    common_cat = set.intersection(*cat_sets) if cat_sets else set()\n",
    "    # excluir target obvios de num si molestan\n",
    "    return sorted(list(common_num)), sorted(list(common_bin)), sorted(list(common_cat))\n",
    "\n",
    "def run_logistic_block(df, y_col, x_cols, thr_mode=\"Manual\", thr=0.5, c_fp=10000, c_fn=80000, prec_min=0.6, test_size=0.30, imb_method=\"Ninguno\"):\n",
    "    base = df[x_cols + [y_col]].copy()\n",
    "    vals = base[y_col].dropna().unique().tolist()\n",
    "    if len(vals) != 2:\n",
    "        return None\n",
    "    mapping = {vals[0]:0, vals[1]:1}\n",
    "    base['__y__'] = base[y_col].map(mapping)\n",
    "    base = base.replace([np.inf,-np.inf], np.nan).dropna(subset=x_cols + ['__y__'])\n",
    "    if base['__y__'].nunique() < 2:\n",
    "        return None\n",
    "    X = base[x_cols].astype(float).to_numpy()\n",
    "    y = base['__y__'].to_numpy(dtype=int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "    if imb_method == \"SMOTE (over-sampling)\":\n",
    "        sm = SMOTE(random_state=42); X_train_s, y_train = sm.fit_resample(X_train_s, y_train)\n",
    "    elif imb_method == \"Under-sampling\":\n",
    "        rus = RandomUnderSampler(random_state=42); X_train_s, y_train = rus.fit_resample(X_train_s, y_train)\n",
    "    if imb_method == \"class_weight='balanced'\":\n",
    "        clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "    y_proba = clf.predict_proba(X_test_s)[:,1]\n",
    "\n",
    "    def pick_threshold_by_f1(y_true, y_score):\n",
    "        p, r, th = precision_recall_curve(y_true, y_score)\n",
    "        f1 = 2*(p*r)/np.clip(p+r, 1e-12, None)\n",
    "        best_idx = np.nanargmax(f1[:-1])\n",
    "        return th[best_idx]\n",
    "    def pick_threshold_by_cost(y_true, y_score, c_fp, c_fn):\n",
    "        ths = np.linspace(0.0,1.0,1001)\n",
    "        best_th, best_cost = 0.5, np.inf\n",
    "        for t in ths:\n",
    "            y_pred = (y_score>=t).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            cost = fp*c_fp + fn*c_fn\n",
    "            if cost < best_cost:\n",
    "                best_cost, best_th = cost, t\n",
    "        return best_th\n",
    "    def pick_threshold_by_recall_with_prec_min(y_true, y_score, prec_min=0.6):\n",
    "        p, r, th = precision_recall_curve(y_true, y_score)\n",
    "        valid = np.where(p[:-1] >= prec_min)[0]\n",
    "        if len(valid)==0: return 0.5\n",
    "        best_idx = valid[np.argmax(r[valid])]\n",
    "        return th[best_idx]\n",
    "\n",
    "    if thr_mode==\"F1 óptimo\":\n",
    "        thr = pick_threshold_by_f1(y_test, y_proba)\n",
    "    elif thr_mode==\"Minimizar costo\":\n",
    "        thr = pick_threshold_by_cost(y_test, y_proba, c_fp, c_fn)\n",
    "    elif thr_mode==\"Maximizar recall con precisión mínima\":\n",
    "        thr = pick_threshold_by_recall_with_prec_min(y_test, y_proba, prec_min=prec_min)\n",
    "    # Manual: se respeta valor de thr\n",
    "\n",
    "    y_pred = (y_proba>=thr).astype(int)\n",
    "    acc   = accuracy_score(y_test, y_pred)\n",
    "    bacc  = balanced_accuracy_score(y_test, y_pred)\n",
    "    prec1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    rec1  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    f1m   = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    auc   = roc_auc_score(y_test, y_proba)\n",
    "    auprc = average_precision_score(y_test, y_proba)\n",
    "    cm    = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "\n",
    "    # Figuras\n",
    "    labels_disp = [list(mapping.keys())[0], list(mapping.keys())[1]]\n",
    "    fig_cm = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"],\n",
    "        y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"],\n",
    "        colorscale=\"Oranges\", showscale=True, hoverongaps=False\n",
    "    ))\n",
    "    ann = []\n",
    "    tags = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ann.append(dict(\n",
    "                x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"][j],\n",
    "                y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"][i],\n",
    "                text=f\"{tags[i,j]}: {cm[i,j]}\",\n",
    "                showarrow=False,\n",
    "                font=dict(color=\"white\" if cm[i,j] > cm.max()/2 else \"black\")\n",
    "            ))\n",
    "    fig_cm.update_layout(title=f\"Matriz de confusión · umbral={thr:.2f}\", annotations=ann, width=520, height=520)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    fig_roc = go.Figure()\n",
    "    fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={auc:.3f})\"))\n",
    "    fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Aleatorio\", line=dict(dash=\"dot\")))\n",
    "    fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "\n",
    "    p, r, th = precision_recall_curve(y_test, y_proba)\n",
    "    fig_pr = go.Figure()\n",
    "    fig_pr.add_trace(go.Scatter(x=r, y=p, mode=\"lines\", name=f\"PR (AP={auprc:.3f})\"))\n",
    "    fig_pr.update_layout(title=\"Curva Precisión-Recall (clase 1)\", xaxis_title=\"Recall\", yaxis_title=\"Precisión\")\n",
    "\n",
    "    fig_prob = px.strip(\n",
    "        x=[labels_disp[i] for i in y_test], y=y_proba,\n",
    "        labels={\"x\":\"Clase real\", \"y\":\"Probabilidad P(Y=1)\"},\n",
    "        title=\"Distribución de probabilidades por clase real\"\n",
    "    )\n",
    "    fig_prob.add_hline(y=thr, line_dash=\"dot\", annotation_text=f\"Umbral {thr:.2f}\")\n",
    "\n",
    "    met_tab = pd.DataFrame({\n",
    "        \"Métrica\": [\"Exactitud\",\"Balanced accuracy\",\"Precisión (1)\",\"Recall (1)\",\"F1 (1)\",\"ROC-AUC\",\"AP (PR)\"],\n",
    "        \"Valor\":   [acc, bacc, prec1, rec1, f1m, auc, auprc]\n",
    "    })\n",
    "    return dict(\n",
    "        metrics=met_tab, cm_fig=fig_cm, roc_fig=fig_roc, pr_fig=fig_pr, prob_fig=fig_prob,\n",
    "        thr=thr, mapping=mapping\n",
    "    )\n",
    "\n",
    "# Carga inicial\n",
    "df, Lista = load_country_df(\"Alemania\")\n",
    "\n",
    "##########\n",
    "# Header\n",
    "col_logo, col_title = st.columns([1,5], vertical_alignment=\"center\")\n",
    "with col_logo:\n",
    "    st.image(\"assets/Logo3.jpg\", width=90)\n",
    "with col_title:\n",
    "    st.markdown(\"\"\"\n",
    "        # Airbnb Data Analysis\n",
    "        <span style=\"color:#767676\">Listados, precios y comportamiento de oferta</span>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Sidebar\n",
    "st.sidebar.image(\"assets/Logoo.jpg\", use_container_width=True)\n",
    "st.sidebar.caption(\"Análisis exploratorio y modelos\")\n",
    "st.sidebar.markdown(\"---\")\n",
    "modo_presentacion = st.sidebar.toggle(\"Modo presentación\", value=False)\n",
    "country = st.sidebar.selectbox(\"País\", list(COUNTRY_FILES.keys()), index=0)\n",
    "df, Lista = load_country_df(country)\n",
    "View = st.sidebar.selectbox(\n",
    "    label='Tipo de análisis',\n",
    "    options=['Extracción de Características', 'Regresión Lineal', 'Regresión No Lineal', 'Regresión Logística', 'Comparar países'],\n",
    "    index=0\n",
    ")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 1 — Extracción de características\n",
    "if View == \"Extracción de Características\":\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Filas\", f\"{len(df):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col2:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Tipos de propiedad\", df['property_type'].nunique() if 'property_type' in df.columns else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        med_price = np.nanmean(df['price_eur']) if 'price_eur' in df.columns else np.nan\n",
    "        st.metric(\"Media de precio\", f\"€{med_price:,.0f}\" if np.isfinite(med_price) else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col4:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        superhosts = int((df['host_is_superhost'] == 1).sum()) if 'host_is_superhost' in df.columns else 0\n",
    "        st.metric(\"Superhosts\", superhosts)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    Variable_Cat = st.sidebar.selectbox(\"Variable categórica a analizar\", options=Lista)\n",
    "    Tabla_frecuencias = df[Variable_Cat].value_counts(dropna=False).reset_index().head(10)\n",
    "    Tabla_frecuencias.columns = ['categorias', 'frecuencia']\n",
    "\n",
    "    st.title(\"Extracción de Características\")\n",
    "    st.caption('Se muestran máximo las 10 categorías con más frecuencia.')\n",
    "\n",
    "    Contenedor_A, Contenedor_B = st.columns(2)\n",
    "    with Contenedor_A:\n",
    "        st.subheader(\"Distribución por categoría (Bar Plot)\")\n",
    "        fig_bar = px.bar(Tabla_frecuencias, x='categorias', y='frecuencia', color='categorias')\n",
    "        st.plotly_chart(fig_bar, use_container_width=True)\n",
    "    with Contenedor_B:\n",
    "        st.subheader(\"Proporción por categoría (Pie Chart)\")\n",
    "        fig_pie = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia')\n",
    "        st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "    Contenedor_C, Contenedor_D = st.columns(2)\n",
    "    with Contenedor_C:\n",
    "        st.subheader(\"Gráfico tipo anillo\")\n",
    "        fig_donut = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia', hole=0.5)\n",
    "        st.plotly_chart(fig_donut, use_container_width=True)\n",
    "    with Contenedor_D:\n",
    "        st.subheader(\"Tendencia acumulada (Área)\")\n",
    "        fig_area = px.area(Tabla_frecuencias.sort_values(by='frecuencia', ascending=False),\n",
    "                           x='categorias', y='frecuencia')\n",
    "        st.plotly_chart(fig_area, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Análisis más profundo\")\n",
    "\n",
    "    if Variable_Cat in ['room_type', 'property_type', 'price_cat'] and 'price' in df.columns:\n",
    "        st.write(\"**Relación entre categorías y precio (Boxplot):**\")\n",
    "        fig_box = px.box(df, x=Variable_Cat, y='price', color=Variable_Cat)\n",
    "        st.plotly_chart(fig_box, use_container_width=True)\n",
    "    else:\n",
    "        st.write(\"**Heatmap de proporciones:**\")\n",
    "        heat_df = pd.crosstab(index=df[Variable_Cat], columns='count', normalize='columns') * 100\n",
    "        fig_heat = px.imshow(heat_df, color_continuous_scale=CONT_GRADIENT, title=\"Proporción por categoría\")\n",
    "        st.plotly_chart(fig_heat, use_container_width=True)\n",
    "\n",
    "    if not modo_presentacion:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Tabla de frecuencias\")\n",
    "        st.dataframe(Tabla_frecuencias.style.background_gradient(cmap='Reds'), use_container_width=True)\n",
    "\n",
    "    gallery_block(country)\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 2 — Regresión Lineal\n",
    "if View == \"Regresión Lineal\":\n",
    "    st.title(\"Regresión Lineal\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    st.subheader(\"Regresión lineal simple\")\n",
    "    colL, colR = st.columns(2)\n",
    "    with colL:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rl_y\")\n",
    "    with colR:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=Lista_num, key=\"rl_x\")\n",
    "\n",
    "    X, y, dropped = _clean_xy(numeric_df, Variable_y, [Variable_x])\n",
    "    if dropped > 0 and not modo_presentacion:\n",
    "        st.info(f\"Se descartaron {dropped} filas con NaN/Inf para el ajuste.\")\n",
    "    if len(y) < 3:\n",
    "        st.error(\"No hay suficientes filas válidas para ajustar el modelo.\")\n",
    "        st.stop()\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    coef_Deter_simple = model.score(X= X, y= y)\n",
    "    coef_Correl_simple = np.sqrt(abs(coef_Deter_simple))\n",
    "\n",
    "    coef_df_simple = pd.DataFrame({\n",
    "        \"Variable\": [Variable_x],\n",
    "        \"Coeficiente\": [model.coef_[0]],\n",
    "        \"Intercepto\": [model.intercept_],\n",
    "        \"R\": [coef_Correl_simple],\n",
    "        \"R^2\": [coef_Deter_simple]\n",
    "    })\n",
    "    if not modo_presentacion:\n",
    "        st.dataframe(coef_df_simple, use_container_width=True)\n",
    "\n",
    "    fig_scat = px.scatter(numeric_df, x=Variable_x, y=Variable_y, opacity=0.6, title=\"Dispersión y recta ajustada\")\n",
    "    order_idx = np.argsort(X[:, 0])\n",
    "    fig_scat.add_trace(go.Scatter(\n",
    "        x=X[order_idx, 0], y=y_pred[order_idx],\n",
    "        mode=\"lines\", name=\"Predicción de Y\"\n",
    "    ))\n",
    "    st.plotly_chart(fig_scat, use_container_width=True)\n",
    "\n",
    "    resid = y - y_pred\n",
    "    fig_res = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"},\n",
    "                         title=\"Residuos vs Predicción (diagnóstico)\")\n",
    "    fig_res.add_hline(y=0, line_dash=\"dot\")\n",
    "    st.plotly_chart(fig_res, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Regresión lineal múltiple\")\n",
    "    col1, col2 = st.columns([1,2])\n",
    "    with col1:\n",
    "        Variable_y_M = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rlm_y\")\n",
    "    with col2:\n",
    "        Variables_x_M = st.multiselect(\"Variables independientes (X)\", options= Lista_num, key=\"rlm_xs\")\n",
    "\n",
    "    if len(Variables_x_M) >= 1:\n",
    "        X_M, y_M, droppedM = _clean_xy(numeric_df, Variable_y_M, Variables_x_M)\n",
    "        if droppedM > 0 and not modo_presentacion:\n",
    "            st.info(f\"Se descartaron {droppedM} filas con NaN/Inf para el ajuste múltiple.\")\n",
    "        if len(y_M) < max(3, len(Variables_x_M)+1):\n",
    "            st.error(\"No hay suficientes filas válidas para el modelo múltiple.\")\n",
    "            st.stop()\n",
    "\n",
    "        Model_M = LinearRegression()\n",
    "        Model_M.fit(X_M, y_M)\n",
    "        y_pred_M = Model_M.predict(X_M)\n",
    "\n",
    "        coef_Deter_multiple = Model_M.score(X=X_M, y=y_M)\n",
    "        coef_Correl_multiple = np.sqrt(abs(coef_Deter_multiple))\n",
    "\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x_M,\n",
    "            \"Coeficiente\": [Model_M.intercept_] + list(Model_M.coef_)\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        met_tab = pd.DataFrame({'R^2': [coef_Deter_multiple], 'R ': [coef_Correl_multiple]})\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        fig_pred = px.scatter(x=y_M, y=y_pred_M, labels={\"x\":\"Y real \", \"y\": \"Y predicciones\"}, title=\"Comparación Y Real vs Y Predicciones\")\n",
    "        fig_pred.add_trace(go.Scatter(x=[y_M.min(), y_M.max()], y=[y_M.min(), y_M.max()], mode=\"lines\", name=\"Línea ideal\", line=dict(dash=\"dot\")))\n",
    "        st.plotly_chart(fig_pred, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Selecciona al menos 1 variable para el modelo múltiple.\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 3 — Regresión No Lineal\n",
    "if View == \"Regresión No Lineal\":\n",
    "    st.title(\"Regresión No Lineal\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float','float64','int','int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    contA, contB = st.columns(2)\n",
    "    with contA:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rnl_y_cf\")\n",
    "    with contB:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=[c for c in Lista_num if c != Variable_y], key=\"rnl_x_cf\")\n",
    "\n",
    "    modelos = [\n",
    "        \"Función cuadrática (a*x**2 + b*x + c)\",\n",
    "        \"Función exponencial (a*np.exp(-b*x)+c)\",\n",
    "        \"Función potencia (a*x**b)\",\n",
    "        \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\"\n",
    "    ]\n",
    "    Modelo = st.selectbox(\"Elige modelo no lineal\", options=modelos, key=\"rnl_modelo_cf\")\n",
    "\n",
    "    df_nl = numeric_df[[Variable_x, Variable_y]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(df_nl) < 3:\n",
    "        st.error(\"Datos insuficientes tras limpiar NaN/Inf para ajustar el modelo no lineal.\")\n",
    "        st.stop()\n",
    "\n",
    "    x = df_nl[Variable_x].to_numpy(dtype=float)\n",
    "    y = df_nl[Variable_y].to_numpy(dtype=float)\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "\n",
    "    def func_cuad(x, a, b, c): return a*x**2 + b*x + c\n",
    "    def func_cub(x, a, b, c, d): return a*x**3 + b*x**2 + c*x + d\n",
    "    def func_exp(x, a, b, c): return a * np.exp(-b * x) + c\n",
    "    def func_pot(x, a, b): return a * np.power(x, b)\n",
    "\n",
    "    try:\n",
    "        if Modelo == \"Función cuadrática (a*x**2 + b*x + c)\":\n",
    "            pars, cov = curve_fit(func_cuad, x, y, maxfev=20000)\n",
    "            y_pred = func_cuad(x, *pars); y_line = func_cuad(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\":\n",
    "            pars, cov = curve_fit(func_cub, x, y, maxfev=30000)\n",
    "            y_pred = func_cub(x, *pars); y_line = func_cub(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\", \"d\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función exponencial (a*np.exp(-b*x)+c)\":\n",
    "            mask = np.isfinite(y)\n",
    "            if np.sum(mask) < 3: st.error(\"No hay suficientes datos válidos para el modelo exponencial.\"); st.stop()\n",
    "            pars, cov = curve_fit(func_exp, x, y, maxfev=30000)\n",
    "            y_pred = func_exp(x, *pars); y_line = func_exp(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función potencia (a*x**b)\":\n",
    "            mask = (x > 0) & (y > 0) & np.isfinite(x) & np.isfinite(y)\n",
    "            if mask.sum() < 3: st.error(\"Para potencia se requieren suficientes valores con x>0 e y>0.\"); st.stop()\n",
    "            x_pos, y_pos = x[mask], y[mask]\n",
    "            pars, cov = curve_fit(func_pot, x_pos, y_pos, maxfev=20000)\n",
    "            x_safe = np.clip(x, 1e-12, None); x_sorted_safe = np.clip(x_sorted, 1e-12, None)\n",
    "            y_pred = func_pot(x_safe, *pars); y_line = func_pot(x_sorted_safe, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\"], \"Valor\": pars})\n",
    "        else:\n",
    "            st.warning(\"Selecciona un modelo válido.\"); st.stop()\n",
    "\n",
    "        r2 = r2_score(y, y_pred); r = np.sqrt(abs(r2))\n",
    "\n",
    "        st.markdown(\"**Parámetros estimados (curve_fit):**\")\n",
    "        if not modo_presentacion: st.dataframe(params_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"**Métricas del ajuste:**\")\n",
    "        st.dataframe(pd.DataFrame({\"R^2\":[r2], \"R \":[r]}), use_container_width=True)\n",
    "\n",
    "        fig = px.scatter(x=x, y=y, labels={\"x\": Variable_x, \"y\": Variable_y},\n",
    "                         opacity=0.6, title=f\"{Modelo} — Dispersión y curva ajustada\")\n",
    "        fig.add_trace(go.Scatter(x=x_sorted, y=y_line, mode=\"lines\", name=\"Ŷ (curva)\", line=dict(width=2)))\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        resid = y - y_pred\n",
    "        fig_resid = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"},\n",
    "                               title=\"Residuos vs Predicción\")\n",
    "        fig_resid.add_hline(y=0, line_dash=\"dot\")\n",
    "        st.plotly_chart(fig_resid, use_container_width=True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        st.error(f\"No convergió el ajuste: {e}.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error durante el ajuste: {e}\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 4 — Regresión Logística\n",
    "if View == \"Regresión Logística\":\n",
    "    st.title(\"Regresión Logística\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64'])\n",
    "    Lista_num  = list(numeric_df.columns)\n",
    "\n",
    "    dico_cols = []\n",
    "    for col in df.columns:\n",
    "        vals = df[col].dropna().unique()\n",
    "        if len(vals) == 2:\n",
    "            dico_cols.append(col)\n",
    "\n",
    "    if len(dico_cols) == 0:\n",
    "        st.warning(\"No se detectaron variables binarias en el dataset.\"); st.stop()\n",
    "\n",
    "    Variable_y = st.sidebar.selectbox(\"Variable dependiente (Y, binaria)\", options=dico_cols)\n",
    "    Variables_x = st.sidebar.multiselect(\"Variables independientes (X, numéricas)\", options=Lista_num)\n",
    "\n",
    "    test_size = st.sidebar.slider(\"Tamaño de prueba\", 0.1, 0.5, 0.30, 0.05)\n",
    "    thr = st.sidebar.slider(\"Umbral de clasificación\", 0.05, 0.95, 0.50, 0.01)\n",
    "\n",
    "    if len(Variables_x) == 0:\n",
    "        st.info(\"Selecciona al menos una variable independiente (X).\")\n",
    "    else:\n",
    "        base = df[Variables_x + [Variable_y]].copy()\n",
    "        vals = base[Variable_y].dropna().unique().tolist()\n",
    "        if len(vals) != 2:\n",
    "            st.error(f\"La variable '{Variable_y}' debe tener exactamente 2 clases. Encontradas: {vals}\")\n",
    "            st.stop()\n",
    "\n",
    "        mapping = {vals[0]: 0, vals[1]: 1}\n",
    "        base['__y__'] = base[Variable_y].map(mapping)\n",
    "        base = base.replace([np.inf, -np.inf], np.nan).dropna(subset=Variables_x + ['__y__'])\n",
    "        if base['__y__'].nunique() < 2:\n",
    "            st.error(\"Tras limpiar datos, solo queda una clase en Y.\"); st.stop()\n",
    "\n",
    "        X = base[Variables_x].astype(float).to_numpy()\n",
    "        y = base['__y__'].to_numpy(dtype=int)\n",
    "        clases = vals\n",
    "\n",
    "        st.sidebar.markdown(\"### Manejo de desbalance\")\n",
    "        imb_method = st.sidebar.selectbox(\"Método\", [\"Ninguno\",\"class_weight='balanced'\",\"SMOTE (over-sampling)\",\"Under-sampling\"])\n",
    "\n",
    "        st.sidebar.markdown(\"### Estrategia de umbral\")\n",
    "        thr_mode = st.sidebar.selectbox(\"Seleccionar umbral por…\", [\"Manual\", \"F1 óptimo\", \"Minimizar costo\", \"Maximizar recall con precisión mínima\"])\n",
    "        prec_min = None; c_fp = None; c_fn = None\n",
    "        if thr_mode == \"Manual\":\n",
    "            thr = st.sidebar.slider(\"Umbral de clasificación\", 0.01, 0.99, thr, 0.01)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            prec_min = st.sidebar.slider(\"Precisión mínima requerida\", 0.1, 0.99, 0.6, 0.01)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            c_fp = st.sidebar.number_input(\"Costo por FP\", min_value=0, value=10000, step=1000)\n",
    "            c_fn = st.sidebar.number_input(\"Costo por FN\", min_value=0, value=80000, step=1000)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "        escalar = StandardScaler()\n",
    "        X_train_s = escalar.fit_transform(X_train)\n",
    "        X_test_s  = escalar.transform(X_test)\n",
    "\n",
    "        if imb_method == \"SMOTE (over-sampling)\":\n",
    "            sm = SMOTE(random_state=42); X_train_s, y_train = sm.fit_resample(X_train_s, y_train)\n",
    "        elif imb_method == \"Under-sampling\":\n",
    "            rus = RandomUnderSampler(random_state=42); X_train_s, y_train = rus.fit_resample(X_train_s, y_train)\n",
    "\n",
    "        if imb_method == \"class_weight='balanced'\":\n",
    "            algoritmo = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        else:\n",
    "            algoritmo = LogisticRegression(max_iter=1000)\n",
    "        algoritmo.fit(X_train_s, y_train)\n",
    "\n",
    "        y_proba = algoritmo.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "        def pick_threshold_by_f1(y_true, y_score):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            f1 = 2 * (p*r) / np.clip(p+r, 1e-12, None); best_idx = np.nanargmax(f1[:-1])\n",
    "            return th[best_idx], f1[best_idx], p[best_idx], r[best_idx]\n",
    "\n",
    "        def pick_threshold_by_cost(y_true, y_score, c_fp, c_fn):\n",
    "            ths = np.linspace(0.0, 1.0, 1001); best_th, best_cost = 0.5, np.inf\n",
    "            for t in ths:\n",
    "                y_pred = (y_score >= t).astype(int)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "                cost = fp * c_fp + fn * c_fn\n",
    "                if cost < best_cost: best_cost, best_th = cost, t\n",
    "            return best_th, best_cost\n",
    "\n",
    "        def pick_threshold_by_recall_with_prec_min(y_true, y_score, prec_min=0.6):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            valid = np.where(p[:-1] >= prec_min)[0]\n",
    "            if len(valid) == 0: return 0.5, 0.0, 0.0\n",
    "            best_idx = valid[np.argmax(r[valid])]; return th[best_idx], r[best_idx], p[best_idx]\n",
    "\n",
    "        if thr_mode == \"F1 óptimo\":\n",
    "            thr, best_f1, best_p, best_r = pick_threshold_by_f1(y_test, y_proba)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            thr, best_cost = pick_threshold_by_cost(y_test, y_proba, c_fp, c_fn)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            thr, best_r, best_p = pick_threshold_by_recall_with_prec_min(y_test, y_proba, prec_min=prec_min)\n",
    "\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "        acc     = accuracy_score(y_test, y_pred)\n",
    "        bacc    = balanced_accuracy_score(y_test, y_pred)\n",
    "        prec_c0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        prec_c1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        rec_c0  = recall_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        rec_c1  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        f1_min  = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        auc     = roc_auc_score(y_test, y_proba)\n",
    "        auprc   = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        met_rows = [\n",
    "            (\"Exactitud\", acc),\n",
    "            (\"Balanced accuracy\", bacc),\n",
    "            (f\"Precision ({clases[0]})\", prec_c0),\n",
    "            (f\"Precision ({clases[1]})\", prec_c1),\n",
    "            (f\"Sensibilidad ({clases[0]})\", rec_c0),\n",
    "            (f\"Sensibilidad ({clases[1]})\", rec_c1),\n",
    "            (f\"F1 ({clases[1]})\", f1_min),\n",
    "            (\"ROC-AUC\", auc)\n",
    "        ]\n",
    "        if thr_mode == \"Minimizar costo\":\n",
    "            met_rows.append((\"Costo total (FP/FN)\", best_cost))\n",
    "\n",
    "        met_tab = pd.DataFrame(met_rows, columns=[\"Métrica\", \"Valor\"])\n",
    "        st.subheader(\"Métricas\")\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        prev = y_test.mean()\n",
    "        if prec_c1 == 1.0 and rec_c1 < 0.15:\n",
    "            st.warning(\"La precisión de la clase minoritaria es 1.0 pero el recall es muy bajo. Ajusta umbral o balanceo.\")\n",
    "        if acc > 0.9 and bacc < 0.65 and prev < 0.25:\n",
    "            st.info(\"La exactitud es alta por el desbalance. Revisa balanced accuracy, AUPRC y F1 de la minoritaria.\")\n",
    "\n",
    "        coef = algoritmo.coef_[0]; intercepto = algoritmo.intercept_[0]\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x,\n",
    "            \"Coeficiente (log-odds)\": [intercepto] + list(coef),\n",
    "            \"Odds Ratio (exp(coef))\": [np.exp(intercepto)] + list(np.exp(coef))\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.subheader(\"Coeficientes del modelo\")\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        matriz = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        labels_disp = [clases[0], clases[1]]\n",
    "        fig_cm = go.Figure(data=go.Heatmap(\n",
    "            z=matriz,\n",
    "            x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"],\n",
    "            y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"],\n",
    "            colorscale=\"Oranges\", showscale=True, hoverongaps=False\n",
    "        ))\n",
    "        ann = []\n",
    "        tags = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ann.append(dict(\n",
    "                    x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"][j],\n",
    "                    y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"][i],\n",
    "                    text=f\"{tags[i,j]}: {matriz[i,j]}\",\n",
    "                    showarrow=False,\n",
    "                    font=dict(color=\"white\" if matriz[i,j] > matriz.max()/2 else \"black\")\n",
    "                ))\n",
    "        fig_cm.update_layout(title=f\"Matriz de confusión (umbral={thr:.2f})\", annotations=ann, width=520, height=520)\n",
    "        st.plotly_chart(fig_cm, use_container_width=False)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        fig_roc = go.Figure()\n",
    "        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={auc:.3f})\"))\n",
    "        fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Aleatorio\", line=dict(dash=\"dot\")))\n",
    "        fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "        st.plotly_chart(fig_roc, use_container_width=True)\n",
    "\n",
    "        p, r, th = precision_recall_curve(y_test, y_proba)\n",
    "        fig_pr = go.Figure()\n",
    "        fig_pr.add_trace(go.Scatter(x=r, y=p, mode=\"lines\", name=f\"PR (AP={auprc:.3f})\"))\n",
    "        fig_pr.update_layout(title=\"Curva Precisión-Recall (clase 1)\", xaxis_title=\"Recall\", yaxis_title=\"Precisión\")\n",
    "        st.plotly_chart(fig_pr, use_container_width=True)\n",
    "\n",
    "        fig_prob = px.strip(\n",
    "            x=[labels_disp[i] for i in y_test], y=y_proba,\n",
    "            labels={\"x\":\"Clase real\", \"y\":\"Probabilidad P(Y=1)\"},\n",
    "            title=\"Distribución de probabilidades por clase real\"\n",
    "        )\n",
    "        fig_prob.add_hline(y=thr, line_dash=\"dot\", annotation_text=f\"Umbral {thr:.2f}\")\n",
    "        st.plotly_chart(fig_prob, use_container_width=True)\n",
    "\n",
    "        st.caption(f\"Mapeo interno (solo para el modelo): {clases[0]} → 0, {clases[1]} → 1. Prevalencia clase 1 (test): {prev:.3f}\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 5 — COMPARAR PAÍSES (Nueva)\n",
    "if View == \"Comparar países\":\n",
    "    st.title(\"Comparación de países (Alemania · Valencia · Estocolmo · México)\")\n",
    "    st.caption(\"Misma métrica y visual por país, en una sola vista.\")\n",
    "\n",
    "    # Cargar todos los países\n",
    "    dfs = {}\n",
    "    listas_cat = {}\n",
    "    for c in COUNTRY_FILES.keys():\n",
    "        dfi, Li = load_country_df(c)\n",
    "        dfs[c] = dfi\n",
    "        listas_cat[c] = set(Li).intersection(set(dfi.columns))\n",
    "\n",
    "    common_num, common_bin, common_cat = get_common_lists(dfs)\n",
    "\n",
    "    # Sub-vistas\n",
    "    subview = st.radio(\"Sub-vista\", [\"Extracción comparada\", \"Regresión logística comparada\"], horizontal=True)\n",
    "\n",
    "    if subview == \"Extracción comparada\":\n",
    "        if len(common_cat)==0:\n",
    "            st.error(\"No hay columnas categóricas en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "        var_cat = st.selectbox(\"Variable categórica común\", options=sorted(common_cat), index=sorted(common_cat).index(\"room_type\") if \"room_type\" in common_cat else 0)\n",
    "\n",
    "        # KPI's por país (fila completa)\n",
    "        st.markdown(\"### KPI's por país\")\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            with st.container():\n",
    "                kpis_block(dfs[c], c)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        st.markdown(\"### Extracción (4× gráficas por país)\")\n",
    "        # Grilla 2x2 por país con (bar, pie, donut, área) + detalle (box/heatmap) + galería\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            st.subheader(f\"{c}\")\n",
    "            tabla, fig_bar, fig_pie, fig_donut, fig_area, detail_fig = extraction_charts(dfs[c], var_cat)\n",
    "            colA, colB = st.columns(2)\n",
    "            with colA: st.plotly_chart(fig_bar, use_container_width=True)\n",
    "            with colB: st.plotly_chart(fig_pie, use_container_width=True)\n",
    "            colC, colD = st.columns(2)\n",
    "            with colC: st.plotly_chart(fig_donut, use_container_width=True)\n",
    "            with colD: st.plotly_chart(fig_area, use_container_width=True)\n",
    "\n",
    "            st.plotly_chart(detail_fig, use_container_width=True)\n",
    "\n",
    "            if not modo_presentacion:\n",
    "                with st.expander(f\"Tabla de frecuencias · {c}\"):\n",
    "                    st.dataframe(tabla.style.background_gradient(cmap='Reds'), use_container_width=True)\n",
    "\n",
    "            with st.expander(f\"Galería · {c}\"):\n",
    "                gallery_block(c)\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "    else:\n",
    "        # Logística comparada\n",
    "        if len(common_bin)==0:\n",
    "            st.error(\"No hay variables binarias en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "        if len(common_num)==0:\n",
    "            st.error(\"No hay variables numéricas en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.markdown(\"### Parámetros comunes\")\n",
    "        y_col = st.selectbox(\"Variable Y (binaria, común)\", options=common_bin)\n",
    "        x_cols = st.multiselect(\"Variables X (numéricas, comunes)\", options=common_num, default=[c for c in common_num if c not in [y_col]][:3])\n",
    "        test_size = st.slider(\"Tamaño de prueba\", 0.1, 0.5, 0.30, 0.05)\n",
    "\n",
    "        colU, colV, colW = st.columns(3)\n",
    "        with colU:\n",
    "            imb_method = st.selectbox(\"Manejo de desbalance\", [\"Ninguno\",\"class_weight='balanced'\",\"SMOTE (over-sampling)\",\"Under-sampling\"])\n",
    "        with colV:\n",
    "            thr_mode = st.selectbox(\"Umbral por\", [\"Manual\",\"F1 óptimo\",\"Minimizar costo\",\"Maximizar recall con precisión mínima\"])\n",
    "        with colW:\n",
    "            thr_manual = st.slider(\"Umbral (si Manual)\", 0.01, 0.99, 0.50, 0.01)\n",
    "\n",
    "        colX, colY = st.columns(2)\n",
    "        with colX:\n",
    "            c_fp = st.number_input(\"Costo por FP (si Minimizar costo)\", min_value=0, value=10000, step=1000)\n",
    "        with colY:\n",
    "            c_fn = st.number_input(\"Costo por FN (si Minimizar costo)\", min_value=0, value=80000, step=1000)\n",
    "\n",
    "        prec_min = st.slider(\"Precisión mínima (si Máx. recall)\", 0.1, 0.99, 0.60, 0.01)\n",
    "\n",
    "        if len(x_cols)==0:\n",
    "            st.info(\"Selecciona al menos 1 X para correr comparación.\")\n",
    "            st.stop()\n",
    "\n",
    "        # Ejecutar por país\n",
    "        results = {}\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            res = run_logistic_block(\n",
    "                dfs[c], y_col, x_cols,\n",
    "                thr_mode=thr_mode,\n",
    "                thr=thr_manual,\n",
    "                c_fp=c_fp, c_fn=c_fn,\n",
    "                prec_min=prec_min,\n",
    "                test_size=test_size,\n",
    "                imb_method=imb_method\n",
    "            )\n",
    "            if res is not None:\n",
    "                results[c] = res\n",
    "\n",
    "        if len(results)==0:\n",
    "            st.error(\"No se pudo entrenar el modelo en ninguno de los países (revisa datos y clases).\")\n",
    "            st.stop()\n",
    "\n",
    "        st.markdown(\"### Métricas comparadas\")\n",
    "        # Tabla apilada por país\n",
    "        tabs = st.tabs(list(results.keys()))\n",
    "        for tab, (c, res) in zip(tabs, results.items()):\n",
    "            with tab:\n",
    "                st.dataframe(res[\"metrics\"], use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Matrices de confusión por país\")\n",
    "        # Grilla 2x2\n",
    "        countries = list(results.keys())\n",
    "        rows = [countries[:2], countries[2:4]]\n",
    "        for row in rows:\n",
    "            cols = st.columns(len(row))\n",
    "            for i, c in enumerate(row):\n",
    "                with cols[i]:\n",
    "                    st.markdown(f\"**{c}**\")\n",
    "                    st.plotly_chart(results[c][\"cm_fig\"], use_container_width=True)\n",
    "\n",
    "        with st.expander(\"Curvas ROC por país\"):\n",
    "            cols = st.columns(2)\n",
    "            items = list(results.items())\n",
    "            for i, (c, res) in enumerate(items):\n",
    "                with cols[i%2]:\n",
    "                    st.markdown(f\"**{c}**\"); st.plotly_chart(res[\"roc_fig\"], use_container_width=True)\n",
    "\n",
    "        with st.expander(\"Curvas Precisión-Recall por país\"):\n",
    "            cols = st.columns(2)\n",
    "            items = list(results.items())\n",
    "            for i, (c, res) in enumerate(items):\n",
    "                with cols[i%2]:\n",
    "                    st.markdown(f\"**{c}**\"); st.plotly_chart(res[\"pr_fig\"], use_container_width=True)\n",
    "\n",
    "        with st.expander(\"Distribución de probabilidades por país\"):\n",
    "            cols = st.columns(2)\n",
    "            items = list(results.items())\n",
    "            for i, (c, res) in enumerate(items):\n",
    "                with cols[i%2]:\n",
    "                    st.markdown(f\"**{c}**\"); st.plotly_chart(res[\"prob_fig\"], use_container_width=True)\n",
    "\n",
    "# FOOTER\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style=\"text-align:center; opacity:0.8; font-size:0.9rem;\">\n",
    "© Proyecto para Gestión de Proyectos — Dashboard creado por <b>Los Guaranies</b> con ayuda de IA y profe Freddy/Malu.  \n",
    "<br> Construido con Streamlit, Plotly y Python.\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3767aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dashboard_Final.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dashboard_Final.py\n",
    "# Dashboard Final equipo integrando en las vistas a los 4 países - Proyecto Airbnb\n",
    "# Versión final\n",
    "\n",
    "##########\n",
    "# Importar librerías\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, roc_auc_score, roc_curve, classification_report, f1_score,\n",
    "    precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "##########\n",
    "# Configuración global\n",
    "st.set_page_config(\n",
    "    page_title=\"Airbnb (Data Web)\",\n",
    "    page_icon=\"assets/icon.jpg\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Paleta Airbnb\n",
    "AIRBNB_RED   = \"#FF5A5F\"\n",
    "AIRBNB_TEAL  = \"#00A699\"\n",
    "AIRBNB_ORANGE= \"#FC642D\"\n",
    "AIRBNB_GRAY  = \"#BFBFBF\"\n",
    "AIRBNB_DARK_BG = \"#0E1117\"\n",
    "AIRBNB_CARD   = \"#151A22\"\n",
    "AIRBNB_BORDER = \"#232A35\"\n",
    "CONT_GRADIENT = \"Reds\"\n",
    "\n",
    "##########\n",
    "# CSS Look & Feel Airbnb\n",
    "st.markdown(f\"\"\"\n",
    "<style>\n",
    ".block-container {{ padding-top: 1.2rem; padding-bottom: 2rem; }}\n",
    "html, body, [data-testid=\"stAppViewContainer\"], section[data-testid=\"stSidebar\"] {{\n",
    "    background: radial-gradient(circle at 30% 30%, #131722 0%, #0E1117 100%) !important;\n",
    "    color: white !important;\n",
    "}}\n",
    "section[data-testid=\"stSidebar\"] {{ border-right: 1px solid {AIRBNB_BORDER}; }}\n",
    ".air-card {{\n",
    "    border: 1px solid {AIRBNB_BORDER};\n",
    "    border-radius:16px; padding:1rem;\n",
    "    background:{AIRBNB_CARD};\n",
    "}}\n",
    ".stButton>button {{\n",
    "    background:{AIRBNB_RED}; color:white; border-radius:12px; border:none;\n",
    "    padding:.6rem 1rem; font-weight:600;\n",
    "}}\n",
    ".stButton>button:hover {{ opacity:.9 }}\n",
    ".stDataFrame, .stTable {{ color: white !important; }}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Plotly: plantilla Airbnb\n",
    "AIRBNB_COLORWAY = [\"#FF5A5F\", \"#00A699\", \"#FC642D\", \"#BFBFBF\", \"#767676\"]\n",
    "pio.templates[\"airbnb_dark\"] = pio.templates[\"plotly_dark\"]\n",
    "pio.templates[\"airbnb_dark\"].layout.colorway = AIRBNB_COLORWAY\n",
    "px.defaults.template = \"airbnb_dark\"\n",
    "px.defaults.color_continuous_scale = CONT_GRADIENT\n",
    "px.defaults.height = 420\n",
    "\n",
    "##########\n",
    "# Multi-país\n",
    "COUNTRY_FILES = {\n",
    "    \"Alemania\": \"Berlin_Final.csv\",\n",
    "    \"Valencia\": \"Valencia_Final.csv\",\n",
    "    \"Estocolmo\": \"Estocolmo_Final.csv\",\n",
    "    \"Mexico\": \"Mexico_Final.csv\",\n",
    "}\n",
    "\n",
    "COUNTRY_IMAGES = {\n",
    "    \"Alemania\": [\"assets/Berlin1.jpg\", \"assets/Berlin3.jpg\", \"assets/Berlin2.jpg\"],\n",
    "    \"Valencia\": [\"assets/Valencia1.jpg\", \"assets/Valencia2.jpg\", \"assets/Valencia3.jpg\"],\n",
    "    \"Estocolmo\": [\"assets/Estocolmo1.jpg\", \"assets/Estocolmo2.jpg\", \"assets/Estocolmo3.jpg\"],\n",
    "    \"Mexico\": [\"assets/Mexico1.jpg\", \"assets/Mexico2.jpg\", \"assets/Mexico3.jpg\"],\n",
    "}\n",
    "\n",
    "##########\n",
    "# Normalización\n",
    "BIN_TRUE = {\"t\",\"true\",\"True\",1,\"1\",True}\n",
    "BIN_FALSE= {\"f\",\"false\",\"False\",0,\"0\",False}\n",
    "\n",
    "def _normalize_binary(series):\n",
    "    s = series.copy()\n",
    "    return s.apply(lambda v: 1 if v in BIN_TRUE else (0 if v in BIN_FALSE else np.nan)).astype(\"float\")\n",
    "\n",
    "def _normalize_df(df_raw):\n",
    "    df = df_raw.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\", na=False)]\n",
    "    df = df.drop(['latitude','longitude','first_review','last_review','host_since', 'price', 'estimated_revenue_l365d','source','id', 'scrape_id'],\n",
    "                 axis=1, errors=\"ignore\")\n",
    "    if 'id' in df.columns:\n",
    "        df['id'] = df['id'].astype(str)\n",
    "    if 'host_id' in df.columns:\n",
    "        df['host_id'] = df['host_id'].astype(str)\n",
    "    for col in ['host_is_superhost','host_identity_verified','instant_bookable']:\n",
    "        if col in df.columns:\n",
    "            df[col] = _normalize_binary(df[col])\n",
    "    for col in ['host_response_rate','host_acceptance_rate','price','estimated_revenue_l365d','price_eur']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def _clean_xy(df_base, y_col, x_cols):\n",
    "    work = df_base[x_cols + [y_col]].replace([np.inf, -np.inf], np.nan)\n",
    "    before = len(work)\n",
    "    work = work.dropna()\n",
    "    after = len(work)\n",
    "    X = work[x_cols].to_numpy(dtype=float)\n",
    "    y = work[y_col].to_numpy(dtype=float)\n",
    "    return X, y, before - after\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_country_df(country: str):\n",
    "    path = COUNTRY_FILES[country]\n",
    "    raw = pd.read_csv(path)\n",
    "    df = _normalize_df(raw)\n",
    "    Lista = [\n",
    "        'host_is_superhost','host_identity_verified','host_response_time',\n",
    "        'host_response_rate','host_acceptance_rate','host_total_listings_count',\n",
    "        'host_verifications','room_type','property_type','price_cat'\n",
    "    ]\n",
    "    return df, Lista\n",
    "\n",
    "def kpis_block(df, country):\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(f\"{country} · Filas\", f\"{len(df):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col2:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(f\"{country} · Tipos de propiedad\", df['property_type'].nunique() if 'property_type' in df.columns else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        med_price = np.nanmean(df['price_eur']) if 'price_eur' in df.columns else np.nan\n",
    "        st.metric(f\"{country} · Media precio\", f\"€{med_price:,.0f}\" if np.isfinite(med_price) else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col4:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        superhosts = int((df['host_is_superhost'] == 1).sum()) if 'host_is_superhost' in df.columns else 0\n",
    "        st.metric(f\"{country} · Superhosts\", superhosts)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "def extraction_tables_and_figs(df, var_cat: str):\n",
    "    tabla = df[var_cat].value_counts(dropna=False).reset_index().head(10)\n",
    "    tabla.columns = ['categorias','frecuencia']\n",
    "    fig_bar = px.bar(tabla, x='categorias', y='frecuencia', color='categorias', title=None)\n",
    "    fig_pie = px.pie(tabla, names='categorias', values='frecuencia', title=None)\n",
    "    fig_donut = px.pie(tabla, names='categorias', values='frecuencia', hole=0.5, title=None)\n",
    "    fig_area = px.area(tabla.sort_values('frecuencia', ascending=False), x='categorias', y='frecuencia', title=None)\n",
    "    heat_df = pd.crosstab(index=df[var_cat], columns='count', normalize='columns') * 100\n",
    "    fig_heat = px.imshow(heat_df, color_continuous_scale=CONT_GRADIENT, title=None)\n",
    "    return tabla, fig_bar, fig_pie, fig_donut, fig_area, fig_heat\n",
    "    \n",
    "def gallery_block(country):\n",
    "    st.markdown(f\"**Galería:** {country} — Airbnb\")\n",
    "    imgs = COUNTRY_IMAGES.get(country, [])\n",
    "    gcols = st.columns(3)\n",
    "    for i, path in enumerate(imgs[:3]):\n",
    "        with gcols[i]:\n",
    "            try:\n",
    "                st.image(path, use_container_width=True)\n",
    "            except Exception:\n",
    "                st.write(\"🖼️ Imagen no encontrada\")\n",
    "\n",
    "def get_common_lists(dfs_dict):\n",
    "    num_sets, bin_sets, cat_sets = [], [], []\n",
    "    for _, df in dfs_dict.items():\n",
    "        num_cols = set(df.select_dtypes(include=['float','float64','int','int64']).columns.tolist())\n",
    "        bin_cols = set([c for c in df.columns if df[c].dropna().nunique()==2])\n",
    "        cat_cols = set([c for c in df.columns if df[c].dtype=='object' or df[c].dtype.name=='category'])\n",
    "        cat_cols |= set([c for c in ['room_type','property_type','price_cat','host_response_time'] if c in df.columns])\n",
    "        num_sets.append(num_cols); bin_sets.append(bin_cols); cat_sets.append(cat_cols)\n",
    "    common_num = set.intersection(*num_sets) if num_sets else set()\n",
    "    common_bin = set.intersection(*bin_sets) if bin_sets else set()\n",
    "    common_cat = set.intersection(*cat_sets) if cat_sets else set()\n",
    "    return sorted(list(common_num)), sorted(list(common_bin)), sorted(list(common_cat))\n",
    "\n",
    "def run_logistic_block(df, y_col, x_cols, thr_mode=\"Manual\", thr=0.5, c_fp=10000, c_fn=80000,\n",
    "                       prec_min=0.6, test_size=0.30, imb_method=\"Ninguno\"):\n",
    "    # Asegura que y_col sea un string escalar\n",
    "    if not isinstance(y_col, str):\n",
    "        if isinstance(y_col, (list, tuple, np.ndarray)) and len(y_col) > 0:\n",
    "            y_col = y_col[0]\n",
    "        else:\n",
    "            y_col = str(y_col)\n",
    "\n",
    "    # Evita que Y esté en X (por si el usuario la seleccionó por error)\n",
    "    x_cols = [x for x in x_cols if x != y_col]\n",
    "\n",
    "    # Si por esta limpieza te quedas sin X, aborta con None\n",
    "    if len(x_cols) == 0:\n",
    "        return None\n",
    "\n",
    "    # Construye base y fuerza Series para Y (no DataFrame)\n",
    "    base = df[x_cols + [y_col]].copy()\n",
    "    y_obj = base[y_col]\n",
    "    if isinstance(y_obj, pd.DataFrame):\n",
    "        # Si por alguna razón llega como DF (p.ej. columnas duplicadas), toma la primera\n",
    "        y_obj = y_obj.iloc[:, 0]\n",
    "\n",
    "    # Obtén clases de Y (exactamente dos)\n",
    "    vals = pd.Series(y_obj).dropna().astype(object).unique().tolist()\n",
    "    if len(vals) != 2:\n",
    "        return None\n",
    "\n",
    "    # Mapeo a {0,1} preservando el orden de aparición\n",
    "    mapping = {vals[0]: 0, vals[1]: 1}\n",
    "    base['__y__'] = y_obj.map(mapping)\n",
    "\n",
    "    # Limpieza de NaN/Inf\n",
    "    base = base.replace([np.inf, -np.inf], np.nan).dropna(subset=x_cols + ['__y__'])\n",
    "    if base['__y__'].nunique() < 2:\n",
    "        return None\n",
    "\n",
    "    X = base[x_cols].astype(float).to_numpy()\n",
    "    y = base['__y__'].to_numpy(dtype=int)\n",
    "\n",
    "    # Split + escala\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "    # Re-muestreo\n",
    "    if imb_method == \"SMOTE (over-sampling)\":\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_s, y_train = sm.fit_resample(X_train_s, y_train)\n",
    "    elif imb_method == \"Under-sampling\":\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train_s, y_train = rus.fit_resample(X_train_s, y_train)\n",
    "\n",
    "    # Modelo\n",
    "    if imb_method == \"class_weight='balanced'\":\n",
    "        clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "\n",
    "    # Probabilidades\n",
    "    y_proba = clf.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "    # Selectores de umbral\n",
    "    def pick_threshold_by_f1(y_true, y_score):\n",
    "        p, r, th = precision_recall_curve(y_true, y_score)\n",
    "        f1 = 2 * (p * r) / np.clip(p + r, 1e-12, None)\n",
    "        best_idx = np.nanargmax(f1[:-1])\n",
    "        return th[best_idx]\n",
    "\n",
    "    def pick_threshold_by_cost(y_true, y_score, c_fp, c_fn):\n",
    "        ths = np.linspace(0.0, 1.0, 1001)\n",
    "        best_th, best_cost = 0.5, np.inf\n",
    "        for t in ths:\n",
    "            y_pred = (y_score >= t).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            cost = fp * c_fp + fn * c_fn\n",
    "            if cost < best_cost:\n",
    "                best_cost, best_th = cost, t\n",
    "        return best_th\n",
    "\n",
    "    def pick_threshold_by_recall_with_prec_min(y_true, y_score, prec_min=0.6):\n",
    "        p, r, th = precision_recall_curve(y_true, y_score)\n",
    "        valid = np.where(p[:-1] >= prec_min)[0]\n",
    "        if len(valid) == 0:\n",
    "            return 0.5\n",
    "        best_idx = valid[np.argmax(r[valid])]\n",
    "        return th[best_idx]\n",
    "\n",
    "    # Determina umbral\n",
    "    if thr_mode == \"F1 óptimo\":\n",
    "        thr = pick_threshold_by_f1(y_test, y_proba)\n",
    "    elif thr_mode == \"Minimizar costo\":\n",
    "        thr = pick_threshold_by_cost(y_test, y_proba, c_fp, c_fn)\n",
    "    elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "        thr = pick_threshold_by_recall_with_prec_min(y_test, y_proba, prec_min=prec_min)\n",
    "    # si es Manual, se respeta el thr que viene\n",
    "\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "    # Métricas\n",
    "    acc   = accuracy_score(y_test, y_pred)\n",
    "    bacc  = balanced_accuracy_score(y_test, y_pred)\n",
    "    prec1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    rec1  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    f1m   = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "    auc   = roc_auc_score(y_test, y_proba)\n",
    "    auprc = average_precision_score(y_test, y_proba)\n",
    "    cm    = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "    # Figuras\n",
    "    labels_disp = [list(mapping.keys())[0], list(mapping.keys())[1]]\n",
    "    fig_cm = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"],\n",
    "        y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"],\n",
    "        colorscale=\"Oranges\", showscale=True, hoverongaps=False\n",
    "    ))\n",
    "    ann = []\n",
    "    tags = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ann.append(dict(\n",
    "                x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"][j],\n",
    "                y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"][i],\n",
    "                text=f\"{tags[i,j]}: {cm[i,j]}\",\n",
    "                showarrow=False,\n",
    "                font=dict(color=\"white\" if cm[i,j] > cm.max()/2 else \"black\")\n",
    "            ))\n",
    "    fig_cm.update_layout(title=f\"Matriz de confusión · umbral={thr:.2f}\", annotations=ann, width=520, height=520)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    fig_roc = go.Figure()\n",
    "    fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={auc:.3f})\"))\n",
    "    fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Aleatorio\", line=dict(dash=\"dot\")))\n",
    "    fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "\n",
    "    p, r, th = precision_recall_curve(y_test, y_proba)\n",
    "    fig_pr = go.Figure()\n",
    "    fig_pr.add_trace(go.Scatter(x=r, y=p, mode=\"lines\", name=f\"PR (AP={auprc:.3f})\"))\n",
    "    fig_pr.update_layout(title=\"Curva Precisión-Recall (clase 1)\", xaxis_title=\"Recall\", yaxis_title=\"Precisión\")\n",
    "\n",
    "    met_tab = pd.DataFrame({\n",
    "        \"Métrica\": [\"Exactitud\",\"Balanced accuracy\",\"Precisión (1)\",\"Recall (1)\",\"F1 (1)\",\"ROC-AUC\",\"AP (PR)\"],\n",
    "        \"Valor\":   [acc, bacc, prec1, rec1, f1m, auc, auprc]\n",
    "    })\n",
    "\n",
    "    return dict(\n",
    "        metrics=met_tab, cm_fig=fig_cm, roc_fig=fig_roc, pr_fig=fig_pr,\n",
    "        thr=thr, mapping=mapping\n",
    "    )\n",
    "\n",
    "\n",
    "# Carga inicial\n",
    "df, Lista = load_country_df(\"Alemania\")\n",
    "\n",
    "##########\n",
    "# Header\n",
    "col_logo, col_title = st.columns([1,5], vertical_alignment=\"center\")\n",
    "with col_logo:\n",
    "    st.image(\"assets/Logo3.jpg\", width=90)\n",
    "with col_title:\n",
    "    st.markdown(\"\"\"\n",
    "        # Airbnb Data Analysis\n",
    "        <span style=\"color:#767676\">Listados, precios y comportamiento de oferta</span>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "##########\n",
    "# Sidebar\n",
    "st.sidebar.image(\"assets/Logoo.jpg\", use_container_width=True)\n",
    "st.sidebar.caption(\"Análisis exploratorio y modelos\")\n",
    "st.sidebar.markdown(\"---\")\n",
    "modo_presentacion = st.sidebar.toggle(\"Modo presentación\", value=False)\n",
    "country = st.sidebar.selectbox(\"País\", list(COUNTRY_FILES.keys()), index=0)\n",
    "df, Lista = load_country_df(country)\n",
    "View = st.sidebar.selectbox(\n",
    "    label='Tipo de análisis',\n",
    "    options=['Extracción de Características', 'Regresión Lineal', 'Regresión No Lineal', 'Regresión Logística', 'Comparar países'],\n",
    "    index=0\n",
    ")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 1 — Extracción de características (individual)\n",
    "if View == \"Extracción de Características\":\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Filas\", f\"{len(df):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col2:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Tipos de propiedad\", df['property_type'].nunique() if 'property_type' in df.columns else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        med_price = np.nanmean(df['price_eur']) if 'price_eur' in df.columns else np.nan\n",
    "        st.metric(\"Media de precio\", f\"€{med_price:,.0f}\" if np.isfinite(med_price) else \"—\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    with col4:\n",
    "        st.markdown('<div class=\"air-card\">', unsafe_allow_html=True)\n",
    "        superhosts = int((df['host_is_superhost'] == 1).sum()) if 'host_is_superhost' in df.columns else 0\n",
    "        st.metric(\"Superhosts\", superhosts)\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    Variable_Cat = st.sidebar.selectbox(\"Variable categórica a analizar\", options=Lista)\n",
    "    Tabla_frecuencias = df[Variable_Cat].value_counts(dropna=False).reset_index().head(10)\n",
    "    Tabla_frecuencias.columns = ['categorias', 'frecuencia']\n",
    "\n",
    "    st.title(\"Extracción de Características\")\n",
    "    st.caption('Se muestran máximo las 10 categorías con más frecuencia.')\n",
    "\n",
    "    Contenedor_A, Contenedor_B = st.columns(2)\n",
    "    with Contenedor_A:\n",
    "        st.subheader(\"Distribución por categoría (Bar Plot)\")\n",
    "        fig_bar = px.bar(Tabla_frecuencias, x='categorias', y='frecuencia', color='categorias')\n",
    "        st.plotly_chart(fig_bar, use_container_width=True)\n",
    "    with Contenedor_B:\n",
    "        st.subheader(\"Proporción por categoría (Pie Chart)\")\n",
    "        fig_pie = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia')\n",
    "        st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "    Contenedor_C, Contenedor_D = st.columns(2)\n",
    "    with Contenedor_C:\n",
    "        st.subheader(\"Gráfico tipo anillo\")\n",
    "        fig_donut = px.pie(Tabla_frecuencias, names='categorias', values='frecuencia', hole=0.5)\n",
    "        st.plotly_chart(fig_donut, use_container_width=True)\n",
    "    with Contenedor_D:\n",
    "        st.subheader(\"Tendencia acumulada (Área)\")\n",
    "        fig_area = px.area(Tabla_frecuencias.sort_values(by='frecuencia', ascending=False),\n",
    "                           x='categorias', y='frecuencia')\n",
    "        st.plotly_chart(fig_area, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Proporción por categoría (Heatmap)\")\n",
    "    heat_df = pd.crosstab(index=df[Variable_Cat], columns='count', normalize='columns') * 100\n",
    "    fig_heat = px.imshow(heat_df, color_continuous_scale=CONT_GRADIENT, title=\"Proporción por categoría\")\n",
    "    st.plotly_chart(fig_heat, use_container_width=True)\n",
    "\n",
    "    if not modo_presentacion:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Tabla de frecuencias\")\n",
    "        st.dataframe(Tabla_frecuencias.style.background_gradient(cmap='Reds'), use_container_width=True)\n",
    "        \n",
    "    gallery_block(country)\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 2 — Regresión Lineal (individual)\n",
    "if View == \"Regresión Lineal\":\n",
    "    st.title(\"Regresión Lineal\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    st.subheader(\"Regresión lineal simple\")\n",
    "    colL, colR = st.columns(2)\n",
    "    with colL:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rl_y\")\n",
    "    with colR:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=Lista_num, key=\"rl_x\")\n",
    "\n",
    "    X, y, dropped = _clean_xy(numeric_df, Variable_y, [Variable_x])\n",
    "    if dropped > 0 and not modo_presentacion:\n",
    "        st.info(f\"Se descartaron {dropped} filas con NaN/Inf para el ajuste.\")\n",
    "    if len(y) < 3:\n",
    "        st.error(\"No hay suficientes filas válidas para ajustar el modelo.\")\n",
    "        st.stop()\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    coef_Deter_simple = model.score(X= X, y= y)\n",
    "    coef_Correl_simple = np.sqrt(abs(coef_Deter_simple))\n",
    "\n",
    "    coef_df_simple = pd.DataFrame({\n",
    "        \"Variable\": [Variable_x],\n",
    "        \"Coeficiente\": [model.coef_[0]],\n",
    "        \"Intercepto\": [model.intercept_],\n",
    "        \"R\": [coef_Correl_simple],\n",
    "        \"R^2\": [coef_Deter_simple]\n",
    "    })\n",
    "    if not modo_presentacion:\n",
    "        st.dataframe(coef_df_simple, use_container_width=True)\n",
    "\n",
    "    fig_scat = px.scatter(numeric_df, x=Variable_x, y=Variable_y, opacity=0.6, title=\"Dispersión y recta ajustada\")\n",
    "    order_idx = np.argsort(X[:, 0])\n",
    "    fig_scat.add_trace(go.Scatter(x=X[order_idx, 0], y=y_pred[order_idx], mode=\"lines\", name=\"Predicción de Y\"))\n",
    "    st.plotly_chart(fig_scat, use_container_width=True)\n",
    "\n",
    "    resid = y - y_pred\n",
    "    fig_res = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"}, title=\"Residuos vs Predicción (diagnóstico)\")\n",
    "    fig_res.add_hline(y=0, line_dash=\"dot\")\n",
    "    st.plotly_chart(fig_res, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Regresión lineal múltiple\")\n",
    "    col1, col2 = st.columns([1,2])\n",
    "    with col1:\n",
    "        Variable_y_M = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rlm_y\")\n",
    "    with col2:\n",
    "        Variables_x_M = st.multiselect(\"Variables independientes (X)\", options= Lista_num, key=\"rlm_xs\")\n",
    "\n",
    "    if len(Variables_x_M) >= 1:\n",
    "        X_M, y_M, droppedM = _clean_xy(numeric_df, Variable_y_M, Variables_x_M)\n",
    "        if droppedM > 0 and not modo_presentacion:\n",
    "            st.info(f\"Se descartaron {droppedM} filas con NaN/Inf para el ajuste múltiple.\")\n",
    "        if len(y_M) < max(3, len(Variables_x_M)+1):\n",
    "            st.error(\"No hay suficientes filas válidas para el modelo múltiple.\")\n",
    "            st.stop()\n",
    "\n",
    "        Model_M = LinearRegression()\n",
    "        Model_M.fit(X_M, y_M)\n",
    "        y_pred_M = Model_M.predict(X_M)\n",
    "\n",
    "        coef_Deter_multiple = Model_M.score(X=X_M, y=y_M)\n",
    "        coef_Correl_multiple = np.sqrt(abs(coef_Deter_multiple))\n",
    "\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x_M,\n",
    "            \"Coeficiente\": [Model_M.intercept_] + list(Model_M.coef_)\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        met_tab = pd.DataFrame({'R^2': [coef_Deter_multiple], 'R ': [coef_Correl_multiple]})\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        fig_pred = px.scatter(x=y_M, y=y_pred_M, labels={\"x\":\"Y real \", \"y\": \"Y predicciones\"}, title=\"Comparación Y Real vs Y Predicciones\")\n",
    "        fig_pred.add_trace(go.Scatter(x=[y_M.min(), y_M.max()], y=[y_M.min(), y_M.max()], mode=\"lines\", name=\"Línea ideal\", line=dict(dash=\"dot\")))\n",
    "        st.plotly_chart(fig_pred, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Selecciona al menos 1 variable para el modelo múltiple.\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 3 — Regresión No Lineal (individual)\n",
    "if View == \"Regresión No Lineal\":\n",
    "    st.title(\"Regresión No Lineal\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float','float64','int','int64']).copy()\n",
    "    Lista_num = list(numeric_df.columns)\n",
    "\n",
    "    contA, contB = st.columns(2)\n",
    "    with contA:\n",
    "        Variable_y = st.selectbox(\"Variable dependiente (Y)\", options=Lista_num, key=\"rnl_y_cf\")\n",
    "    with contB:\n",
    "        Variable_x = st.selectbox(\"Variable independiente (X)\", options=[c for c in Lista_num if c != Variable_y], key=\"rnl_x_cf\")\n",
    "\n",
    "    modelos = [\n",
    "        \"Función cuadrática (a*x**2 + b*x + c)\",\n",
    "        \"Función exponencial (a*np.exp(-b*x)+c)\",\n",
    "        \"Función potencia (a*x**b)\",\n",
    "        \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\"\n",
    "    ]\n",
    "    Modelo = st.selectbox(\"Elige modelo no lineal\", options=modelos, key=\"rnl_modelo_cf\")\n",
    "\n",
    "    df_nl = numeric_df[[Variable_x, Variable_y]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(df_nl) < 3:\n",
    "        st.error(\"Datos insuficientes tras limpiar NaN/Inf para ajustar el modelo no lineal.\")\n",
    "        st.stop()\n",
    "\n",
    "    x = df_nl[Variable_x].to_numpy(dtype=float)\n",
    "    y = df_nl[Variable_y].to_numpy(dtype=float)\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "\n",
    "    def func_cuad(x, a, b, c): return a*x**2 + b*x + c\n",
    "    def func_cub(x, a, b, c, d): return a*x**3 + b*x**2 + c*x + d\n",
    "    def func_exp(x, a, b, c): return a * np.exp(-b * x) + c\n",
    "    def func_pot(x, a, b): return a * np.power(x, b)\n",
    "\n",
    "    try:\n",
    "        if Modelo == \"Función cuadrática (a*x**2 + b*x + c)\":\n",
    "            pars, cov = curve_fit(func_cuad, x, y, maxfev=20000)\n",
    "            y_pred = func_cuad(x, *pars); y_line = func_cuad(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\":\n",
    "            pars, cov = curve_fit(func_cub, x, y, maxfev=30000)\n",
    "            y_pred = func_cub(x, *pars); y_line = func_cub(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\", \"d\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función exponencial (a*np.exp(-b*x)+c)\":\n",
    "            mask = np.isfinite(y)\n",
    "            if np.sum(mask) < 3: st.error(\"No hay suficientes datos válidos para el modelo exponencial.\"); st.stop()\n",
    "            pars, cov = curve_fit(func_exp, x, y, maxfev=30000)\n",
    "            y_pred = func_exp(x, *pars); y_line = func_exp(x_sorted, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\", \"c\"], \"Valor\": pars})\n",
    "        elif Modelo == \"Función potencia (a*x**b)\":\n",
    "            mask = (x > 0) & (y > 0) & np.isfinite(x) & np.isfinite(y)\n",
    "            if mask.sum() < 3: st.error(\"Para potencia se requieren suficientes valores con x>0 e y>0.\"); st.stop()\n",
    "            x_pos, y_pos = x[mask], y[mask]\n",
    "            pars, cov = curve_fit(func_pot, x_pos, y_pos, maxfev=20000)\n",
    "            x_safe = np.clip(x, 1e-12, None); x_sorted_safe = np.clip(x_sorted, 1e-12, None)\n",
    "            y_pred = func_pot(x_safe, *pars); y_line = func_pot(x_sorted_safe, *pars)\n",
    "            params_df = pd.DataFrame({\"Parámetro\": [\"a\", \"b\"], \"Valor\": pars})\n",
    "        else:\n",
    "            st.warning(\"Selecciona un modelo válido.\"); st.stop()\n",
    "\n",
    "        r2 = r2_score(y, y_pred); r = np.sqrt(abs(r2))\n",
    "\n",
    "        st.markdown(\"**Parámetros estimados (curve_fit):**\")\n",
    "        if not modo_presentacion: st.dataframe(params_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"**Métricas del ajuste:**\")\n",
    "        st.dataframe(pd.DataFrame({\"R^2\":[r2], \"R \":[r]}), use_container_width=True)\n",
    "\n",
    "        fig = px.scatter(x=x, y=y, labels={\"x\": Variable_x, \"y\": Variable_y},\n",
    "                         opacity=0.6, title=f\"{Modelo} — Dispersión y curva ajustada\")\n",
    "        fig.add_trace(go.Scatter(x=x_sorted, y=y_line, mode=\"lines\", name=\"Ŷ (curva)\", line=dict(width=2)))\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        resid = y - y_pred\n",
    "        fig_resid = px.scatter(x=y_pred, y=resid, labels={\"x\":\"Ŷ\", \"y\":\"Residual\"},\n",
    "                               title=\"Residuos vs Predicción\")\n",
    "        fig_resid.add_hline(y=0, line_dash=\"dot\")\n",
    "        st.plotly_chart(fig_resid, use_container_width=True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        st.error(f\"No convergió el ajuste: {e}.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error durante el ajuste: {e}\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 4 — Regresión Logística (individual)\n",
    "if View == \"Regresión Logística\":\n",
    "    st.title(\"Regresión Logística\")\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['float', 'float64', 'int', 'int64'])\n",
    "    Lista_num  = list(numeric_df.columns)\n",
    "\n",
    "    dico_cols = []\n",
    "    for col in df.columns:\n",
    "        vals = df[col].dropna().unique()\n",
    "        if len(vals) == 2:\n",
    "            dico_cols.append(col)\n",
    "\n",
    "    if len(dico_cols) == 0:\n",
    "        st.warning(\"No se detectaron variables binarias en el dataset.\"); st.stop()\n",
    "\n",
    "    Variable_y = st.sidebar.selectbox(\"Variable dependiente (Y, binaria)\", options=dico_cols)\n",
    "    Variables_x = st.sidebar.multiselect(\"Variables independientes (X, numéricas)\", options=Lista_num)\n",
    "\n",
    "    test_size = st.sidebar.slider(\"Tamaño de prueba\", 0.1, 0.5, 0.30, 0.05)\n",
    "    thr = st.sidebar.slider(\"Umbral de clasificación\", 0.05, 0.95, 0.50, 0.01)\n",
    "\n",
    "    if len(Variables_x) == 0:\n",
    "        st.info(\"Selecciona al menos una variable independiente (X).\")\n",
    "    else:\n",
    "        base = df[Variables_x + [Variable_y]].copy()\n",
    "        vals = base[Variable_y].dropna().unique().tolist()\n",
    "        if len(vals) != 2:\n",
    "            st.error(f\"La variable '{Variable_y}' debe tener exactamente 2 clases. Encontradas: {vals}\")\n",
    "            st.stop()\n",
    "\n",
    "        mapping = {vals[0]: 0, vals[1]: 1}\n",
    "        base['__y__'] = base[Variable_y].map(mapping)\n",
    "        base = base.replace([np.inf, -np.inf], np.nan).dropna(subset=Variables_x + ['__y__'])\n",
    "        if base['__y__'].nunique() < 2:\n",
    "            st.error(\"Tras limpiar datos, solo queda una clase en Y.\"); st.stop()\n",
    "\n",
    "        X = base[Variables_x].astype(float).to_numpy()\n",
    "        y = base['__y__'].to_numpy(dtype=int)\n",
    "        clases = vals\n",
    "\n",
    "        st.sidebar.markdown(\"### Manejo de desbalance\")\n",
    "        imb_method = st.sidebar.selectbox(\"Método\", [\"Ninguno\",\"class_weight='balanced'\",\"SMOTE (over-sampling)\",\"Under-sampling\"])\n",
    "\n",
    "        st.sidebar.markdown(\"### Estrategia de umbral\")\n",
    "        thr_mode = st.sidebar.selectbox(\"Seleccionar umbral por…\", [\"Manual\", \"F1 óptimo\", \"Minimizar costo\", \"Maximizar recall con precisión mínima\"])\n",
    "        prec_min = None; c_fp = None; c_fn = None\n",
    "        if thr_mode == \"Manual\":\n",
    "            thr = st.sidebar.slider(\"Umbral de clasificación\", 0.01, 0.99, thr, 0.01)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            prec_min = st.sidebar.slider(\"Precisión mínima requerida\", 0.1, 0.99, 0.6, 0.01)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            c_fp = st.sidebar.number_input(\"Costo por FP\", min_value=0, value=10000, step=1000)\n",
    "            c_fn = st.sidebar.number_input(\"Costo por FN\", min_value=0, value=80000, step=1000)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "        escalar = StandardScaler()\n",
    "        X_train_s = escalar.fit_transform(X_train)\n",
    "        X_test_s  = escalar.transform(X_test)\n",
    "\n",
    "        if imb_method == \"SMOTE (over-sampling)\":\n",
    "            sm = SMOTE(random_state=42); X_train_s, y_train = sm.fit_resample(X_train_s, y_train)\n",
    "        elif imb_method == \"Under-sampling\":\n",
    "            rus = RandomUnderSampler(random_state=42); X_train_s, y_train = rus.fit_resample(X_train_s, y_train)\n",
    "\n",
    "        if imb_method == \"class_weight='balanced'\":\n",
    "            algoritmo = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        else:\n",
    "            algoritmo = LogisticRegression(max_iter=1000)\n",
    "        algoritmo.fit(X_train_s, y_train)\n",
    "\n",
    "        y_proba = algoritmo.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "        def pick_threshold_by_f1(y_true, y_score):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            f1 = 2 * (p*r) / np.clip(p+r, 1e-12, None); best_idx = np.nanargmax(f1[:-1])\n",
    "            return th[best_idx], f1[best_idx], p[best_idx], r[best_idx]\n",
    "\n",
    "        def pick_threshold_by_cost(y_true, y_score, c_fp, c_fn):\n",
    "            ths = np.linspace(0.0, 1.0, 1001); best_th, best_cost = 0.5, np.inf\n",
    "            for t in ths:\n",
    "                y_pred = (y_score >= t).astype(int)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "                cost = fp * c_fp + fn * c_fn\n",
    "                if cost < best_cost: best_cost, best_th = cost, t\n",
    "            return best_th, best_cost\n",
    "\n",
    "        def pick_threshold_by_recall_with_prec_min(y_true, y_score, prec_min=0.6):\n",
    "            p, r, th = precision_recall_curve(y_true, y_score)\n",
    "            valid = np.where(p[:-1] >= prec_min)[0]\n",
    "            if len(valid) == 0: return 0.5, 0.0, 0.0\n",
    "            best_idx = valid[np.argmax(r[valid])]; return th[best_idx], r[best_idx], p[best_idx]\n",
    "\n",
    "        if thr_mode == \"F1 óptimo\":\n",
    "            thr, best_f1, best_p, best_r = pick_threshold_by_f1(y_test, y_proba)\n",
    "        elif thr_mode == \"Minimizar costo\":\n",
    "            thr, best_cost = pick_threshold_by_cost(y_test, y_proba, c_fp, c_fn)\n",
    "        elif thr_mode == \"Maximizar recall con precisión mínima\":\n",
    "            thr, best_r, best_p = pick_threshold_by_recall_with_prec_min(y_test, y_proba, prec_min=prec_min)\n",
    "\n",
    "        y_pred = (y_proba >= thr).astype(int)\n",
    "\n",
    "        acc     = accuracy_score(y_test, y_pred)\n",
    "        bacc    = balanced_accuracy_score(y_test, y_pred)\n",
    "        prec_c0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        prec_c1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        rec_c0  = recall_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
    "        rec_c1  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        f1_min  = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        auc     = roc_auc_score(y_test, y_proba)\n",
    "        auprc   = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        met_rows = [\n",
    "            (\"Exactitud\", acc),\n",
    "            (\"Balanced accuracy\", bacc),\n",
    "            (f\"Precision ({clases[0]})\", prec_c0),\n",
    "            (f\"Precision ({clases[1]})\", prec_c1),\n",
    "            (f\"Sensibilidad ({clases[0]})\", rec_c0),\n",
    "            (f\"Sensibilidad ({clases[1]})\", rec_c1),\n",
    "            (f\"F1 ({clases[1]})\", f1_min),\n",
    "            (\"ROC-AUC\", auc)\n",
    "        ]\n",
    "        if thr_mode == \"Minimizar costo\":\n",
    "            met_rows.append((\"Costo total (FP/FN)\", best_cost))\n",
    "\n",
    "        met_tab = pd.DataFrame(met_rows, columns=[\"Métrica\", \"Valor\"])\n",
    "        st.subheader(\"Métricas\")\n",
    "        st.dataframe(met_tab, use_container_width=True)\n",
    "\n",
    "        prev = y_test.mean()\n",
    "        if prec_c1 == 1.0 and rec_c1 < 0.15:\n",
    "            st.warning(\"La precisión de la clase minoritaria es 1.0 pero el recall es muy bajo. Ajusta umbral o balanceo.\")\n",
    "        if acc > 0.9 and bacc < 0.65 and prev < 0.25:\n",
    "            st.info(\"La exactitud es alta por el desbalance. Revisa balanced accuracy, AUPRC y F1 de la minoritaria.\")\n",
    "\n",
    "        coef = algoritmo.coef_[0]; intercepto = algoritmo.intercept_[0]\n",
    "        coef_tab = pd.DataFrame({\n",
    "            \"Variable\": [\"Intercepto\"] + Variables_x,\n",
    "            \"Coeficiente (log-odds)\": [intercepto] + list(coef),\n",
    "            \"Odds Ratio (exp(coef))\": [np.exp(intercepto)] + list(np.exp(coef))\n",
    "        })\n",
    "        if not modo_presentacion:\n",
    "            st.subheader(\"Coeficientes del modelo\")\n",
    "            st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "        matriz = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        labels_disp = [clases[0], clases[1]]\n",
    "        fig_cm = go.Figure(data=go.Heatmap(\n",
    "            z=matriz,\n",
    "            x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"],\n",
    "            y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"],\n",
    "            colorscale=\"Oranges\", showscale=True, hoverongaps=False\n",
    "        ))\n",
    "        ann = []; tags = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ann.append(dict(\n",
    "                    x=[f\"Pred {labels_disp[0]}\", f\"Pred {labels_disp[1]}\"][j],\n",
    "                    y=[f\"Real {labels_disp[0]}\", f\"Real {labels_disp[1]}\"][i],\n",
    "                    text=f\"{tags[i,j]}: {matriz[i,j]}\",\n",
    "                    showarrow=False,\n",
    "                    font=dict(color=\"white\" if matriz[i,j] > matriz.max()/2 else \"black\")\n",
    "                ))\n",
    "        fig_cm.update_layout(title=f\"Matriz de confusión (umbral={thr:.2f})\", annotations=ann, width=520, height=520)\n",
    "        st.plotly_chart(fig_cm, use_container_width=False)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        fig_roc = go.Figure()\n",
    "        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={auc:.3f})\"))\n",
    "        fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Aleatorio\", line=dict(dash=\"dot\")))\n",
    "        fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "        st.plotly_chart(fig_roc, use_container_width=True)\n",
    "\n",
    "        p, r, th = precision_recall_curve(y_test, y_proba)\n",
    "        fig_pr = go.Figure()\n",
    "        fig_pr.add_trace(go.Scatter(x=r, y=p, mode=\"lines\", name=f\"PR (AP={auprc:.3f})\"))\n",
    "        fig_pr.update_layout(title=\"Curva Precisión-Recall (clase 1)\", xaxis_title=\"Recall\", yaxis_title=\"Precisión\")\n",
    "        st.plotly_chart(fig_pr, use_container_width=True)\n",
    "\n",
    "        fig_prob = px.strip(\n",
    "            x=[labels_disp[i] for i in y_test], y=y_proba,\n",
    "            labels={\"x\":\"Clase real\", \"y\":\"Probabilidad P(Y=1)\"},\n",
    "            title=\"Distribución de probabilidades por clase real\"\n",
    "        )\n",
    "        fig_prob.add_hline(y=thr, line_dash=\"dot\", annotation_text=f\"Umbral {thr:.2f}\")\n",
    "        st.plotly_chart(fig_prob, use_container_width=True)\n",
    "\n",
    "        st.caption(f\"Mapeo interno (solo para el modelo): {clases[0]} → 0, {clases[1]} → 1. Prevalencia clase 1 (test): {prev:.3f}\")\n",
    "\n",
    "##########################################################################################\n",
    "# Vista 5 — COMPARAR PAÍSES (Mejorada)\n",
    "if View == \"Comparar países\":\n",
    "    st.title(\"Comparación de países (Alemania · Valencia · Estocolmo · México)\")\n",
    "    st.caption(\"Misma métrica y visual por país, en una sola vista.\")\n",
    "\n",
    "    # Cargar todos los países\n",
    "    dfs = {}\n",
    "    for c in COUNTRY_FILES.keys():\n",
    "        dfi, _ = load_country_df(c)\n",
    "        dfs[c] = dfi\n",
    "\n",
    "    common_num, common_bin, common_cat = get_common_lists(dfs)\n",
    "\n",
    "    # Sub-vistas actualizadas\n",
    "    subview = st.radio(\n",
    "        \"Sub-vista\",\n",
    "        [\"Extracción comparada\", \"Regresión logística comparada\", \"Regresión lineal comparada\", \"Regresión no lineal comparada\"],\n",
    "        horizontal=True\n",
    "    )\n",
    "\n",
    "    # ============= EXTRACCIÓN COMPARADA (con KPIs + filas por tipo de gráfico + heatmaps + tablas) =============\n",
    "    if subview == \"Extracción comparada\":\n",
    "        if len(common_cat)==0:\n",
    "            st.error(\"No hay columnas categóricas en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "        var_cat = st.selectbox(\"Variable categórica común\", options=sorted(common_cat), index=sorted(common_cat).index(\"room_type\") if \"room_type\" in common_cat else 0)\n",
    "\n",
    "        # KPIs por país (en una sola fila)\n",
    "        #st.markdown(\"### KPI's por país\")\n",
    "        #cols = st.columns(4)\n",
    "        #for i, c in enumerate(COUNTRY_FILES.keys()):\n",
    "        #    with cols[i]:\n",
    "        #        kpis_block(dfs[c], c)\n",
    "\n",
    "        # KPI's por país (fila completa)\n",
    "        st.markdown(\"### KPI's por país\")\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            with st.container():\n",
    "                kpis_block(dfs[c], c)\n",
    "\n",
    "        # Preparar tablas y figuras por país (una sola vez)\n",
    "        cache = {}\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            # devuelve: tabla, fig_bar, fig_pie, fig_donut, fig_area, fig_heat\n",
    "            cache[c] = extraction_tables_and_figs(dfs[c], var_cat)\n",
    "        \n",
    "        countries = list(COUNTRY_FILES.keys())\n",
    "\n",
    "        def _grid_2x2(fig_key_idx: int, titulo: str):\n",
    "            st.subheader(titulo)\n",
    "            rows = [countries[:2], countries[2:4]]\n",
    "            for row in rows:\n",
    "                row_cols = st.columns(2)\n",
    "                for j, cc in enumerate(row):\n",
    "                    with row_cols[j]:\n",
    "                        st.markdown(f\"**{cc}**\")\n",
    "                        st.plotly_chart(cache[cc][fig_key_idx], use_container_width=True)\n",
    "\n",
    "        # 2x2 por tipo de gráfico (mismo tipo por fila)\n",
    "        _grid_2x2(fig_key_idx=1, titulo=\"Distribución por categoría (Bar) — Comparación directa\")\n",
    "        _grid_2x2(fig_key_idx=2, titulo=\"Proporción por categoría (Pie) — Comparación directa\")\n",
    "        _grid_2x2(fig_key_idx=3, titulo=\"Gráfico tipo anillo (Donut) — Comparación directa\")\n",
    "        _grid_2x2(fig_key_idx=4, titulo=\"Tendencia acumulada (Área) — Comparación directa\")\n",
    "        _grid_2x2(fig_key_idx=5, titulo=\"Proporción por categoría (Heatmap) — Comparación directa\")\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Tablas de frecuencias (Top 10) por país\")\n",
    "        tabs = st.tabs(countries)\n",
    "        for t, c in zip(tabs, countries):\n",
    "            with t:\n",
    "                tabla = cache[c][0]\n",
    "                st.dataframe(tabla.style.background_gradient(cmap='Reds'), use_container_width=True)\n",
    "        \n",
    "        # Imágenes por país (grid 2x2) — ahora muestra las 3 imágenes por ciudad\n",
    "        st.markdown(\"### Imágenes por país\")\n",
    "        rows_img = [countries[:2], countries[2:4]]\n",
    "        for row in rows_img:\n",
    "            row_cols = st.columns(2)\n",
    "            for j, cc in enumerate(row):\n",
    "                with row_cols[j]:\n",
    "                    st.markdown(f\"**{cc}**\")\n",
    "                    img_list = COUNTRY_IMAGES.get(cc, [])\n",
    "                    if len(img_list) > 0:\n",
    "                        # Muestra hasta 3 imágenes en una fila\n",
    "                        img_cols = st.columns(len(img_list))\n",
    "                        for k, img_path in enumerate(img_list[:3]):\n",
    "                            with img_cols[k]:\n",
    "                                try:\n",
    "                                    st.image(img_path, use_container_width=True)\n",
    "                                except Exception:\n",
    "                                    st.write(\"🖼️ Imagen no encontrada\")\n",
    "                    else:\n",
    "                        st.write(\"Sin imágenes registradas.\")\n",
    "\n",
    "\n",
    "    # ============= LOGÍSTICA COMPARADA (igual que antes) =============\n",
    "    elif subview == \"Regresión logística comparada\":\n",
    "        if len(common_bin)==0:\n",
    "            st.error(\"No hay variables binarias en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "        if len(common_num)==0:\n",
    "            st.error(\"No hay variables numéricas en común en los 4 datasets.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.markdown(\"### Parámetros comunes\")\n",
    "        y_col = st.selectbox(\"Variable Y (binaria, común)\", options=common_bin)\n",
    "        x_cols = st.multiselect(\"Variables X (numéricas, comunes)\", options=common_num, default=[c for c in common_num if c not in [y_col]][:3])\n",
    "        test_size = st.slider(\"Tamaño de prueba\", 0.1, 0.5, 0.30, 0.05)\n",
    "\n",
    "        colU, colV, colW = st.columns(3)\n",
    "        with colU:\n",
    "            imb_method = st.selectbox(\"Manejo de desbalance\", [\"Ninguno\",\"class_weight='balanced'\",\"SMOTE (over-sampling)\",\"Under-sampling\"])\n",
    "        with colV:\n",
    "            thr_mode = st.selectbox(\"Umbral por\", [\"Manual\",\"F1 óptimo\",\"Minimizar costo\",\"Maximizar recall con precisión mínima\"])\n",
    "        with colW:\n",
    "            thr_manual = st.slider(\"Umbral (si Manual)\", 0.01, 0.99, 0.50, 0.01)\n",
    "\n",
    "        colX, colY = st.columns(2)\n",
    "        with colX:\n",
    "            c_fp = st.number_input(\"Costo por FP (si Minimizar costo)\", min_value=0, value=10000, step=1000)\n",
    "        with colY:\n",
    "            c_fn = st.number_input(\"Costo por FN (si Minimizar costo)\", min_value=0, value=80000, step=1000)\n",
    "\n",
    "        prec_min = st.slider(\"Precisión mínima (si Máx. recall)\", 0.1, 0.99, 0.60, 0.01)\n",
    "\n",
    "        if len(x_cols)==0:\n",
    "            st.info(\"Selecciona al menos 1 X para correr comparación.\")\n",
    "            st.stop()\n",
    "\n",
    "        # Ejecutar por país\n",
    "        results = {}\n",
    "        for c in COUNTRY_FILES.keys():\n",
    "            res = run_logistic_block(\n",
    "                dfs[c], y_col, x_cols,\n",
    "                thr_mode=thr_mode,\n",
    "                thr=thr_manual,\n",
    "                c_fp=c_fp, c_fn=c_fn,\n",
    "                prec_min=prec_min,\n",
    "                test_size=test_size,\n",
    "                imb_method=imb_method\n",
    "            )\n",
    "            if res is not None:\n",
    "                results[c] = res\n",
    "\n",
    "        if len(results)==0:\n",
    "            st.error(\"No se pudo entrenar el modelo en ninguno de los países (revisa datos y clases).\")\n",
    "            st.stop()\n",
    "\n",
    "        st.markdown(\"### Métricas comparadas\")\n",
    "        # Tabla apilada por país\n",
    "        tabs = st.tabs(list(results.keys()))\n",
    "        for tab, (c, res) in zip(tabs, results.items()):\n",
    "            with tab:\n",
    "                st.dataframe(res[\"metrics\"], use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Matrices de confusión por país\")\n",
    "        # Grilla 2x2\n",
    "        countries = list(results.keys())\n",
    "        rows = [countries[:2], countries[2:4]]\n",
    "        for row in rows:\n",
    "            cols = st.columns(len(row))\n",
    "            for i, c in enumerate(row):\n",
    "                with cols[i]:\n",
    "                    st.markdown(f\"**{c}**\")\n",
    "                    st.plotly_chart(results[c][\"cm_fig\"], use_container_width=True)\n",
    "\n",
    "        with st.expander(\"Curvas ROC por país\"):\n",
    "            cols = st.columns(2)\n",
    "            items = list(results.items())\n",
    "            for i, (c, res) in enumerate(items):\n",
    "                with cols[i%2]:\n",
    "                    st.markdown(f\"**{c}**\"); st.plotly_chart(res[\"roc_fig\"], use_container_width=True)\n",
    "\n",
    "        with st.expander(\"Curvas Precisión-Recall por país\"):\n",
    "            cols = st.columns(2)\n",
    "            items = list(results.items())\n",
    "            for i, (c, res) in enumerate(items):\n",
    "                with cols[i%2]:\n",
    "                    st.markdown(f\"**{c}**\"); st.plotly_chart(res[\"pr_fig\"], use_container_width=True)\n",
    "\n",
    "\n",
    "\n",
    "    # ============= LINEAL COMPARADA (Simple y Múltiple) =============\n",
    "    elif subview == \"Regresión lineal comparada\":\n",
    "        if len(common_num)==0:\n",
    "            st.error(\"No hay variables numéricas en común en los 4 datasets.\"); st.stop()\n",
    "\n",
    "        tab_simple, tab_multiple = st.tabs([\"Lineal Simple\", \"Lineal Múltiple\"])\n",
    "\n",
    "        # --- SIMPLE ---\n",
    "        with tab_simple:\n",
    "            colA, colB = st.columns(2)\n",
    "            with colA:\n",
    "                y_lin = st.selectbox(\"Y (numérica común)\", options=common_num, key=\"cmp_rl_y\")\n",
    "            with colB:\n",
    "                x_lin = st.selectbox(\"X (numérica común)\", options=[c for c in common_num if c!=y_lin], key=\"cmp_rl_x\")\n",
    "\n",
    "            st.markdown(\"### Dispersión + recta por país\")\n",
    "            cols = st.columns(4)\n",
    "            for i, c in enumerate(COUNTRY_FILES.keys()):\n",
    "                dfi = dfs[c].select_dtypes(include=['float','float64','int','int64'])\n",
    "                if y_lin not in dfi.columns or x_lin not in dfi.columns:\n",
    "                    continue\n",
    "                X, y, dropped = _clean_xy(dfi, y_lin, [x_lin])\n",
    "                if len(y) < 3:\n",
    "                    continue\n",
    "                model = LinearRegression().fit(X, y)\n",
    "                y_pred = model.predict(X)\n",
    "                r2 = model.score(X, y); r = float(np.sqrt(abs(r2)))\n",
    "                fig = px.scatter(dfi, x=x_lin, y=y_lin, opacity=0.6, title=None)\n",
    "                order_idx = np.argsort(X[:,0])\n",
    "                fig.add_trace(go.Scatter(x=X[order_idx,0], y=y_pred[order_idx], mode=\"lines\", name=\"Ŷ\"))\n",
    "                with cols[i]:\n",
    "                    st.markdown(f\"**{c}**  \\nR²: `{r2:.2f}` · R: `{r:.2f}`\")\n",
    "                    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # --- MÚLTIPLE ---\n",
    "        with tab_multiple:\n",
    "            colY, colXs = st.columns([1,2])\n",
    "            with colY:\n",
    "                y_linM = st.selectbox(\"Y (numérica común)\", options=common_num, key=\"cmp_rlm_y\")\n",
    "            with colXs:\n",
    "                xs_linM = st.multiselect(\"X (numéricas comunes)\", options=[c for c in common_num if c!=y_linM], default=[c for c in common_num if c!=y_linM][:3], key=\"cmp_rlm_xs\")\n",
    "\n",
    "            if len(xs_linM)==0:\n",
    "                st.info(\"Selecciona al menos 1 X común.\")\n",
    "            else:\n",
    "                tabs = st.tabs(list(COUNTRY_FILES.keys()))\n",
    "                for t, c in zip(tabs, COUNTRY_FILES.keys()):\n",
    "                    with t:\n",
    "                        dfi = dfs[c].select_dtypes(include=['float','float64','int','int64'])\n",
    "                        if any(col not in dfi.columns for col in [y_linM] + xs_linM):\n",
    "                            st.warning(\"Columna(s) faltante(s) en este país.\")\n",
    "                            continue\n",
    "                        X, y, dropped = _clean_xy(dfi, y_linM, xs_linM)\n",
    "                        if len(y) < max(3, len(xs_linM)+1):\n",
    "                            st.warning(\"Datos insuficientes tras limpieza.\")\n",
    "                            continue\n",
    "                        m = LinearRegression().fit(X, y)\n",
    "                        y_pred = m.predict(X)\n",
    "                        r2 = m.score(X, y); r = float(np.sqrt(abs(r2)))\n",
    "                        coef_tab = pd.DataFrame({\"Variable\": [\"Intercepto\"] + xs_linM,\n",
    "                                                 \"Coeficiente\": [m.intercept_] + list(m.coef_)})\n",
    "                        st.markdown(f\"**{c}** · R²: `{r2:.2f}` · R: `{r:.2f}`\")\n",
    "                        st.dataframe(coef_tab, use_container_width=True)\n",
    "\n",
    "    # ============= NO LINEAL COMPARADA =============\n",
    "    elif subview == \"Regresión no lineal comparada\":\n",
    "        if len(common_num)==0:\n",
    "            st.error(\"No hay variables numéricas en común en los 4 datasets.\"); st.stop()\n",
    "\n",
    "        colA, colB = st.columns(2)\n",
    "        with colA:\n",
    "            y_nl = st.selectbox(\"Y (numérica común)\", options=common_num, key=\"cmp_rnl_y\")\n",
    "        with colB:\n",
    "            x_nl = st.selectbox(\"X (numérica común)\", options=[c for c in common_num if c!=y_nl], key=\"cmp_rnl_x\")\n",
    "\n",
    "        modelos = [\n",
    "            \"Función cuadrática (a*x**2 + b*x + c)\",\n",
    "            \"Función exponencial (a*np.exp(-b*x)+c)\",\n",
    "            \"Función potencia (a*x**b)\",\n",
    "            \"Función cúbica (a*x**3 + b*x**2 + c*x + d)\"\n",
    "        ]\n",
    "        modelo_sel = st.selectbox(\"Modelo no lineal\", options=modelos, key=\"cmp_rnl_model\")\n",
    "\n",
    "        def func_cuad(x, a, b, c): return a*x**2 + b*x + c\n",
    "        def func_cub(x, a, b, c, d): return a*x**3 + b*x**2 + c*x + d\n",
    "        def func_exp(x, a, b, c): return a * np.exp(-b * x) + c\n",
    "        def func_pot(x, a, b): return a * np.power(x, b)\n",
    "\n",
    "        cols = st.columns(4)\n",
    "        for i, c in enumerate(COUNTRY_FILES.keys()):\n",
    "            dfi = dfs[c].select_dtypes(include=['float','float64','int','int64'])\n",
    "            if any(col not in dfi.columns for col in [x_nl, y_nl]):\n",
    "                with cols[i]: st.warning(\"Columnas no disponibles.\"); continue\n",
    "            df_nl = dfi[[x_nl, y_nl]].replace([np.inf,-np.inf], np.nan).dropna()\n",
    "            if len(df_nl) < 3:\n",
    "                with cols[i]: st.warning(\"Datos insuficientes.\"); continue\n",
    "            x = df_nl[x_nl].to_numpy(dtype=float)\n",
    "            y = df_nl[y_nl].to_numpy(dtype=float)\n",
    "            sort_idx = np.argsort(x); xs = x[sort_idx]\n",
    "\n",
    "            try:\n",
    "                if modelo_sel.startswith(\"Función cuadrática\"):\n",
    "                    pars, _ = curve_fit(func_cuad, x, y, maxfev=20000)\n",
    "                    y_pred = func_cuad(x, *pars); y_line = func_cuad(xs, *pars)\n",
    "                elif modelo_sel.startswith(\"Función cúbica\"):\n",
    "                    pars, _ = curve_fit(func_cub, x, y, maxfev=30000)\n",
    "                    y_pred = func_cub(x, *pars); y_line = func_cub(xs, *pars)\n",
    "                elif modelo_sel.startswith(\"Función exponencial\"):\n",
    "                    pars, _ = curve_fit(func_exp, x, y, maxfev=30000)\n",
    "                    y_pred = func_exp(x, *pars); y_line = func_exp(xs, *pars)\n",
    "                else:\n",
    "                    mask = (x>0) & (y>0) & np.isfinite(x) & np.isfinite(y)\n",
    "                    if mask.sum() < 3:\n",
    "                        with cols[i]: st.warning(\"x>0 e y>0 insuficientes para potencia.\"); continue\n",
    "                    xp, yp = x[mask], y[mask]\n",
    "                    pars, _ = curve_fit(func_pot, xp, yp, maxfev=20000)\n",
    "                    xs_safe = np.clip(xs, 1e-12, None); x_safe = np.clip(x, 1e-12, None)\n",
    "                    y_pred = func_pot(x_safe, *pars); y_line = func_pot(xs_safe, *pars)\n",
    "\n",
    "                r2 = r2_score(y, y_pred); r = float(np.sqrt(abs(r2)))\n",
    "                fig = px.scatter(x=x, y=y, labels={\"x\": x_nl, \"y\": y_nl}, opacity=0.6, title=None)\n",
    "                fig.add_trace(go.Scatter(x=xs, y=y_line, mode=\"lines\", name=\"Ŷ\", line=dict(width=2)))\n",
    "                with cols[i]:\n",
    "                    st.markdown(f\"**{c}**  \\nR²: `{r2:.3f}` · R: `{r:.3f}`\")\n",
    "                    st.plotly_chart(fig, use_container_width=True)\n",
    "            except RuntimeError as e:\n",
    "                with cols[i]: st.error(f\"No convergió: {e}\")\n",
    "            except Exception as e:\n",
    "                with cols[i]: st.error(f\"Error: {e}\")\n",
    "\n",
    "# FOOTER\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style=\"text-align:center; opacity:0.8; font-size:0.9rem;\">\n",
    "© Proyecto para Gestión de Proyectos — Dashboard creado por <b>Los Guaranies</b> con ayuda de IA y profe Freddy/Malu.  \n",
    "<br> Construido con Streamlit, Plotly y Python.\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
